[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2025.05.11
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#res>RES</a></li>
    <li><a href=#rvos>RVOS</a></li>
    <li><a href=#rvot>RVOT</a></li>
    <li><a href=#avs>AVS</a></li>
    <li><a href=#3d-res>3D-RES</a></li>
  </ol>
</details>

## RES

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-05-03**|**RESAnything: Attribute Prompting for Arbitrary Referring Segmentation**|Ruiqi Wang et.al.|[2505.02867](http://arxiv.org/abs/2505.02867)|null|
|**2025-04-22**|**Progressive Language-guided Visual Learning for Multi-Task Visual Grounding**|Jingchao Wang et.al.|[2504.16145](http://arxiv.org/abs/2504.16145)|null|
|**2025-05-01**|**LGD: Leveraging Generative Descriptions for Zero-Shot Referring Image Segmentation**|Jiachen Li et.al.|[2504.14467](http://arxiv.org/abs/2504.14467)|null|
|**2025-04-17**|**3DResT: A Strong Baseline for Semi-Supervised 3D Referring Expression Segmentation**|Wenxin Chen et.al.|[2504.12599](http://arxiv.org/abs/2504.12599)|null|
|**2025-04-15**|**Aligning Generative Denoising with Discriminative Objectives Unleashes Diffusion for Visual Perception**|Ziqi Pang et.al.|[2504.11457](http://arxiv.org/abs/2504.11457)|**[link](https://github.com/ziqipang/addp)**|
|**2025-04-02**|**Towards Unified Referring Expression Segmentation Across Omni-Level Visual Target Granularities**|Jing Liu et.al.|[2504.01954](http://arxiv.org/abs/2504.01954)|null|
|**2025-04-01**|**Hybrid Global-Local Representation with Augmented Spatial Guidance for Zero-Shot Referring Image Segmentation**|Ting Liu et.al.|[2504.00356](http://arxiv.org/abs/2504.00356)|**[link](https://github.com/fhgyuanshen/hybridgl)**|
|**2025-03-17**|**Scale Efficient Training for Large Datasets**|Qing Zhou et.al.|[2503.13385](http://arxiv.org/abs/2503.13385)|null|
|**2025-04-21**|**GroundingSuite: Measuring Complex Multi-Granular Pixel Grounding**|Rui Hu et.al.|[2503.10596](http://arxiv.org/abs/2503.10596)|**[link](https://github.com/hustvl/groundingsuite)**|
|**2025-03-02**|**IteRPrimE: Zero-shot Referring Image Segmentation with Iterative Grad-CAM Refinement and Primary Word Emphasis**|Yuji Wang et.al.|[2503.00936](http://arxiv.org/abs/2503.00936)|**[link](https://github.com/VoyageWang/IteRPrimE)**|
|**2025-02-28**|**AeroReformer: Aerial Referring Transformer for UAV-based Referring Image Segmentation**|Rui Li et.al.|[2502.16680](http://arxiv.org/abs/2502.16680)|**[link](https://github.com/lironui/aeroreformer)**|
|**2025-02-23**|**PixFoundation: Are We Heading in the Right Direction with Pixel-level Vision Foundation Models?**|Mennatullah Siam et.al.|[2502.04192](http://arxiv.org/abs/2502.04192)|**[link](https://github.com/msiam/pixfoundation)**|
|**2025-03-31**|**Know "No'' Better: A Data-Driven Approach for Enhancing Negation Awareness in CLIP**|Junsung Park et.al.|[2501.10913](http://arxiv.org/abs/2501.10913)|null|
|**2025-01-15**|**Densely Connected Parameter-Efficient Tuning for Referring Image Segmentation**|Jiaqi Huang et.al.|[2501.08580](http://arxiv.org/abs/2501.08580)|**[link](https://github.com/jiaqihuang01/detris)**|
|**2025-01-12**|**Multi-task Visual Grounding with Coarse-to-Fine Consistency Constraints**|Ming Dai et.al.|[2501.06710](http://arxiv.org/abs/2501.06710)|**[link](https://github.com/dmmm1997/c3vg)**|
|**2025-01-09**|**IPDN: Image-enhanced Prompt Decoding Network for 3D Referring Expression Segmentation**|Qi Chen et.al.|[2501.04995](http://arxiv.org/abs/2501.04995)|**[link](https://github.com/80chen86/ipdn)**|
|**2025-01-02**|**Hierarchical Alignment-enhanced Adaptive Grounding Network for Generalized Referring Expression Comprehension**|Yaxian Wang et.al.|[2501.01416](http://arxiv.org/abs/2501.01416)|null|
|**2024-12-14**|**Grasp What You Want: Embodied Dexterous Grasping System Driven by Your Voice**|Junliang Li et.al.|[2412.10694](http://arxiv.org/abs/2412.10694)|null|
|**2024-12-22**|**RG-SAN: Rule-Guided Spatial Awareness Network for End-to-End 3D Referring Expression Segmentation**|Changli Wu et.al.|[2412.02402](http://arxiv.org/abs/2412.02402)|**[link](https://github.com/sosppxo/rg-san)**|
|**2024-11-28**|**MaskRIS: Semantic Distortion-aware Data Augmentation for Referring Image Segmentation**|Minhyun Lee et.al.|[2411.19067](http://arxiv.org/abs/2411.19067)|**[link](https://github.com/naver-ai/maskris)**|
|**2024-11-22**|**Instance-Aware Generalized Referring Expression Segmentation**|E-Ro Nguyen et.al.|[2411.15087](http://arxiv.org/abs/2411.15087)|null|
|**2024-11-03**|**Finding NeMo: Negative-mined Mosaic Augmentation for Referring Image Segmentation**|Seongsu Ha et.al.|[2411.01494](http://arxiv.org/abs/2411.01494)|null|
|**2024-10-31**|**SegLLM: Multi-round Reasoning Segmentation**|XuDong Wang et.al.|[2410.18923](http://arxiv.org/abs/2410.18923)|null|
|**2025-02-17**|**Text4Seg: Reimagining Image Segmentation as Text Generation**|Mengcheng Lan et.al.|[2410.09855](http://arxiv.org/abs/2410.09855)|**[link](https://github.com/mc-lan/text4seg)**|
|**2024-12-04**|**Boosting Weakly-Supervised Referring Image Segmentation via Progressive Comprehension**|Zaiquan Yang et.al.|[2410.01544](http://arxiv.org/abs/2410.01544)|null|
|**2024-09-29**|**Fully Aligned Network for Referring Image Segmentation**|Yong Liu et.al.|[2409.19569](http://arxiv.org/abs/2409.19569)|null|
|**2025-02-07**|**A Parameter-Efficient Tuning Framework for Language-guided Object Grounding and Robot Grasping**|Houjian Yu et.al.|[2409.19457](http://arxiv.org/abs/2409.19457)|null|
|**2025-02-11**|**ADEPT: A Noninvasive Method for Determining Elastic Parameters of Valve Tissue**|Wensi Wu et.al.|[2409.19081](http://arxiv.org/abs/2409.19081)|null|
|**2025-02-18**|**PTQ4RIS: Post-Training Quantization for Referring Image Segmentation**|Xiaoyan Jiang et.al.|[2409.17020](http://arxiv.org/abs/2409.17020)|**[link](https://github.com/gugu511yy/ptq4ris)**|
|**2024-09-17**|**Robot Manipulation in Salient Vision through Referring Image Segmentation and Geometric Constraints**|Chen Jiang et.al.|[2409.11518](http://arxiv.org/abs/2409.11518)|null|
|**2024-12-14**|**SAM4MLLM: Enhance Multi-Modal Large Language Model for Referring Expression Segmentation**|Yi-Chia Chen et.al.|[2409.10542](http://arxiv.org/abs/2409.10542)|**[link](https://github.com/ai-application-and-integration-lab/sam4mllm)**|
|**2024-09-19**|**A Simple Baseline with Single-encoder for Referring Image Segmentation**|Seonghoon Yu et.al.|[2408.15521](http://arxiv.org/abs/2408.15521)|null|
|**2024-08-14**|**Cross-aware Early Fusion with Stage-divided Vision and Language Transformer Encoders for Referring Image Segmentation**|Yubin Cho et.al.|[2408.07539](http://arxiv.org/abs/2408.07539)|null|
|**2024-08-07**|**How Well Can Vision Language Models See Image Details?**|Chenhui Gou et.al.|[2408.03940](http://arxiv.org/abs/2408.03940)|null|
|**2024-07-31**|**3D-GRES: Generalized 3D Referring Expression Segmentation**|Changli Wu et.al.|[2407.20664](http://arxiv.org/abs/2407.20664)|**[link](https://github.com/sosppxo/MDIN)**|
|**2024-07-25**|**RefMask3D: Language-Guided Transformer for 3D Referring Segmentation**|Shuting He et.al.|[2407.18244](http://arxiv.org/abs/2407.18244)|**[link](https://github.com/heshuting555/refmask3d)**|
|**2024-07-17**|**Pseudo-RIS: Distinctive Pseudo-supervision Generation for Referring Image Segmentation**|Seonghoon Yu et.al.|[2407.07412](http://arxiv.org/abs/2407.07412)|**[link](https://github.com/seonghoon-yu/pseudo-ris)**|
|**2024-07-02**|**SafaRi:Adaptive Sequence Transformer for Weakly Supervised Referring Expression Segmentation**|Sayan Nag et.al.|[2407.02389](http://arxiv.org/abs/2407.02389)|null|
|**2025-03-10**|**EVF-SAM: Early Vision-Language Fusion for Text-Prompted Segment Anything Model**|Yuxuan Zhang et.al.|[2406.20076](http://arxiv.org/abs/2406.20076)|**[link](https://github.com/hustvl/evf-sam)**|
|**2025-04-11**|**F-LMM: Grounding Frozen Large Multimodal Models**|Size Wu et.al.|[2406.05821](http://arxiv.org/abs/2406.05821)|**[link](https://github.com/wusize/f-lmm)**|
|**2024-06-03**|**SAM as the Guide: Mastering Pseudo-Label Refinement in Semi-Supervised Referring Expression Segmentation**|Danni Yang et.al.|[2406.01451](http://arxiv.org/abs/2406.01451)|**[link](https://github.com/nini0919/semires)**|
|**2024-07-27**|**GOI: Find 3D Gaussians of Interest with an Optimizable Open-vocabulary Semantic-space Hyperplane**|Yansong Qu et.al.|[2405.17596](http://arxiv.org/abs/2405.17596)|null|
|**2024-11-25**|**CoHD: A Counting-Aware Hierarchical Decoding Framework for Generalized Referring Expression Segmentation**|Zhuoyan Luo et.al.|[2405.15658](http://arxiv.org/abs/2405.15658)|**[link](https://github.com/robertluo1/cohd)**|
|**2025-01-06**|**Bring Adaptive Binding Prototypes to Generalized Referring Expression Segmentation**|Weize Li et.al.|[2405.15169](http://arxiv.org/abs/2405.15169)|**[link](https://github.com/buptlwz/mabp)**|
|**2024-05-18**|**Fuse & Calibrate: A bi-directional Vision-Language Guided Framework for Referring Image Segmentation**|Yichen Yan et.al.|[2405.11205](http://arxiv.org/abs/2405.11205)|null|
|**2024-05-21**|**HARIS: Human-Like Attention for Reference Image Segmentation**|Mengxi Zhang et.al.|[2405.10707](http://arxiv.org/abs/2405.10707)|null|
|**2024-05-15**|**Spatial Semantic Recurrent Mining for Referring Image Segmentation**|Jiaxing Yang et.al.|[2405.09006](http://arxiv.org/abs/2405.09006)|null|
|**2024-04-18**|**Curriculum Point Prompting for Weakly-Supervised Referring Image Segmentation**|Qiyuan Dai et.al.|[2404.11998](http://arxiv.org/abs/2404.11998)|null|
|**2024-11-04**|**Vision-Aware Text Features in Referring Image Segmentation: From Object Understanding to Context Understanding**|Hai Nguyen-Truong et.al.|[2404.08590](http://arxiv.org/abs/2404.08590)|null|
|**2024-04-12**|**Calibration & Reconstruction: Deep Integrated Language for Referring Image Segmentation**|Yichen Yan et.al.|[2404.08281](http://arxiv.org/abs/2404.08281)|null|
|**2024-04-27**|**Deep Instruction Tuning for Segment Anything Model**|Xiaorui Huang et.al.|[2404.00650](http://arxiv.org/abs/2404.00650)|**[link](https://github.com/wysnzzzz/dit)**|
|**2024-07-25**|**ReMamber: Referring Image Segmentation with Mamba Twister**|Yuhuan Yang et.al.|[2403.17839](http://arxiv.org/abs/2403.17839)|**[link](https://github.com/yyh-rain-song/ReMamber)**|
|**2024-03-21**|**PSALM: Pixelwise SegmentAtion with Large Multi-Modal Model**|Zheng Zhang et.al.|[2403.14598](http://arxiv.org/abs/2403.14598)|**[link](https://github.com/zamling/psalm)**|
|**2024-06-27**|**Towards Alleviating Text-to-Image Retrieval Hallucination for CLIP in Zero-shot Learning**|Hanyao Wang et.al.|[2402.18400](http://arxiv.org/abs/2402.18400)|null|
|**2024-02-11**|**RESMatch: Referring Expression Segmentation in a Semi-Supervised Manner**|Ying Zang et.al.|[2402.05589](http://arxiv.org/abs/2402.05589)|null|
|**2024-02-04**|**Generalizable Entity Grounding via Assistance of Large Language Model**|Lu Qi et.al.|[2402.02555](http://arxiv.org/abs/2402.02555)|null|
|**2024-01-22**|**Collaborative Position Reasoning Network for Referring Image Segmentation**|Jianjian Cao et.al.|[2401.11775](http://arxiv.org/abs/2401.11775)|null|
|**2023-12-25**|**UniRef++: Segment Every Reference Object in Spatial and Temporal Spaces**|Jiannan Wu et.al.|[2312.15715](http://arxiv.org/abs/2312.15715)|**[link](https://github.com/foundationvision/uniref)**|
|**2024-04-02**|**Rotated Multi-Scale Interaction Network for Referring Remote Sensing Image Segmentation**|Sihan Liu et.al.|[2312.12470](http://arxiv.org/abs/2312.12470)|**[link](https://github.com/lsan2401/rmsin)**|
|**2024-03-25**|**Mask Grounding for Referring Image Segmentation**|Yong Xien Chng et.al.|[2312.12198](http://arxiv.org/abs/2312.12198)|**[link](https://github.com/yxchng/mask-grounding)**|
|**2024-03-21**|**GSVA: Generalized Segmentation via Multimodal Large Language Models**|Zhuofan Xia et.al.|[2312.10103](http://arxiv.org/abs/2312.10103)|**[link](https://github.com/leaplabthu/gsva)**|
|**2024-03-21**|**Unveiling Parts Beyond Objects:Towards Finer-Granularity Referring Expression Segmentation**|Wenxuan Wang et.al.|[2312.08007](http://arxiv.org/abs/2312.08007)|**[link](https://github.com/rubics-xuan/mres)**|
|**2023-12-01**|**Towards Generalizable Referring Image Segmentation via Target Prompt and Visual Coherence**|Yajie Liu et.al.|[2312.00452](http://arxiv.org/abs/2312.00452)|null|
|**2023-11-30**|**InstructSeq: Unifying Vision Tasks with Instruction-conditioned Multi-modal Sequence Generation**|Rongyao Fang et.al.|[2311.18835](http://arxiv.org/abs/2311.18835)|null|
|**2023-11-29**|**Synchronizing Vision and Language: Bidirectional Token-Masking AutoEncoder for Referring Image Segmentation**|Minhyeok Lee et.al.|[2311.17952](http://arxiv.org/abs/2311.17952)|null|
|**2024-05-21**|**RISAM: Referring Image Segmentation via Mutual-Aware Attention Features**|Mengxi Zhang et.al.|[2311.15727](http://arxiv.org/abs/2311.15727)|null|
|**2023-11-22**|**Visual In-Context Prompting**|Feng Li et.al.|[2311.13601](http://arxiv.org/abs/2311.13601)|**[link](https://github.com/ux-decoder/dinov)**|
|**2024-04-26**|**Enhancing Visual Grounding and Generalization: A Multi-Task Cycle Training Approach for Vision-Language Models**|Xiaoyu Yang et.al.|[2311.12327](http://arxiv.org/abs/2311.12327)|null|
|**2023-12-18**|**NExT-Chat: An LMM for Chat, Detection and Segmentation**|Ao Zhang et.al.|[2311.04498](http://arxiv.org/abs/2311.04498)|**[link](https://github.com/next-chatv/next-chat)**|
|**2024-06-02**|**GLaMM: Pixel Grounding Large Multimodal Model**|Hanoona Rasheed et.al.|[2311.03356](http://arxiv.org/abs/2311.03356)|**[link](https://github.com/mbzuai-oryx/groundingLMM)**|
|**2023-11-27**|**Towards Omni-supervised Referring Expression Segmentation**|Minglang Huang et.al.|[2311.00397](http://arxiv.org/abs/2311.00397)|**[link](https://github.com/nineblu/omni-res)**|
|**2023-10-27**|**Text Augmented Spatial-aware Zero-shot Referring Image Segmentation**|Yucheng Suo et.al.|[2310.18049](http://arxiv.org/abs/2310.18049)|null|
|**2024-08-20**|**Segment, Select, Correct: A Framework for Weakly-Supervised Referring Segmentation**|Francisco Eiras et.al.|[2310.13479](http://arxiv.org/abs/2310.13479)|**[link](https://github.com/fgirbal/segment-select-correct)**|
|**2023-09-29**|**Towards Complex-query Referring Image Segmentation: A Novel Benchmark**|Wei Ji et.al.|[2309.17205](http://arxiv.org/abs/2309.17205)|null|
|**2023-09-17**|**CLIPUNetr: Assisting Human-robot Interface for Uncalibrated Visual Servoing Control with CLIP-driven Referring Expression Segmentation**|Chen Jiang et.al.|[2309.09183](http://arxiv.org/abs/2309.09183)|null|
|**2024-10-01**|**From Text to Mask: Localizing Entities Using the Attention of Text-to-Image Diffusion Models**|Changming Xiao et.al.|[2309.04109](http://arxiv.org/abs/2309.04109)|**[link](https://github.com/Big-Brother-Pikachu/Text2Mask)**|
|**2023-09-02**|**Contrastive Grouping with Transformer for Referring Image Segmentation**|Jiajin Tang et.al.|[2309.01017](http://arxiv.org/abs/2309.01017)|**[link](https://github.com/toneyaya/cgformer)**|
|**2023-09-01**|**Ref-Diff: Zero-shot Referring Image Segmentation with Generative Models**|Minheng Ni et.al.|[2308.16777](http://arxiv.org/abs/2308.16777)|null|
|**2023-08-31**|**3D-STMN: Dependency-Driven Superpoint-Text Matching Network for End-to-End 3D Referring Expression Segmentation**|Changli Wu et.al.|[2308.16632](http://arxiv.org/abs/2308.16632)|**[link](https://github.com/sosppxo/3d-stmn)**|
|**2023-10-24**|**Shatter and Gather: Learning Referring Image Segmentation with Text Supervision**|Dongwon Kim et.al.|[2308.15512](http://arxiv.org/abs/2308.15512)|**[link](https://github.com/kdwonn/SaG)**|
|**2023-08-28**|**Referring Image Segmentation Using Text Supervision**|Fang Liu et.al.|[2308.14575](http://arxiv.org/abs/2308.14575)|**[link](https://github.com/fawnliu/tris)**|
|**2023-08-26**|**Beyond One-to-One: Rethinking the Referring Image Segmentation**|Yutao Hu et.al.|[2308.13853](http://arxiv.org/abs/2308.13853)|**[link](https://github.com/toggle1995/ris-dmmi)**|
|**2024-10-12**|**EAVL: Explicitly Align Vision and Language for Referring Image Segmentation**|Yichen Yan et.al.|[2308.09779](http://arxiv.org/abs/2308.09779)|null|
|**2023-07-21**|**Bridging Vision and Language Encoders: Parameter-Efficient Tuning for Referring Image Segmentation**|Zunnan Xu et.al.|[2307.11545](http://arxiv.org/abs/2307.11545)|**[link](https://github.com/kkakkkka/etris)**|
|**2024-09-03**|**RefSAM: Efficiently Adapting Segmenting Anything Model for Referring Video Object Segmentation**|Yonglin Li et.al.|[2307.00997](http://arxiv.org/abs/2307.00997)|**[link](https://github.com/lancasterli/refsam)**|
|**2023-06-19**|**WiCo: Win-win Cooperation of Bottom-up and Top-down Referring Image Segmentation**|Zesen Cheng et.al.|[2306.10750](http://arxiv.org/abs/2306.10750)|null|
|**2024-03-01**|**RRSIS: Referring Remote Sensing Image Segmentation**|Zhenghang Yuan et.al.|[2306.08625](http://arxiv.org/abs/2306.08625)|null|
|**2024-04-07**|**Extending CLIP's Image-Text Alignment to Referring Image Segmentation**|Seoyeon Kim et.al.|[2306.08498](http://arxiv.org/abs/2306.08498)|null|
|**2023-06-01**|**GRES: Generalized Referring Expression Segmentation**|Chang Liu et.al.|[2306.00968](http://arxiv.org/abs/2306.00968)|**[link](https://github.com/henghuiding/ReLA)**|
|**2024-08-12**|**Contextual Object Detection with Multimodal Large Language Models**|Yuhang Zang et.al.|[2305.18279](http://arxiv.org/abs/2305.18279)|**[link](https://github.com/yuhangzang/contextdet)**|
|**2023-05-24**|**Multi-Modal Mutual Attention and Iterative Interaction for Referring Image Segmentation**|Chang Liu et.al.|[2305.15302](http://arxiv.org/abs/2305.15302)|null|
|**2023-05-24**|**MMNet: Multi-Mask Network for Referring Image Segmentation**|Yichen Yan et.al.|[2305.14969](http://arxiv.org/abs/2305.14969)|null|
|**2023-05-21**|**Advancing Referring Expression Segmentation Beyond Single Image**|Yixuan Wu et.al.|[2305.12452](http://arxiv.org/abs/2305.12452)|null|
|**2024-02-14**|**CM-MaskSD: Cross-Modality Masked Self-Distillation for Referring Image Segmentation**|Wenxuan Wang et.al.|[2305.11481](http://arxiv.org/abs/2305.11481)|null|
|**2023-04-12**|**Meta Compositional Referring Expression Segmentation**|Li Xu et.al.|[2304.04415](http://arxiv.org/abs/2304.04415)|null|
|**2023-04-03**|**Zero-shot Referring Image Segmentation with Global-Local Context Features**|Seonghoon Yu et.al.|[2303.17811](http://arxiv.org/abs/2303.17811)|**[link](https://github.com/seonghoon-yu/zero-shot-ris)**|
|**2023-03-11**|**Semantics-Aware Dynamic Localization and Refinement for Referring Image Segmentation**|Zhao Yang et.al.|[2303.06345](http://arxiv.org/abs/2303.06345)|null|
|**2023-03-03**|**Unleashing Text-to-Image Diffusion Models for Visual Perception**|Wenliang Zhao et.al.|[2303.02153](http://arxiv.org/abs/2303.02153)|**[link](https://github.com/wl-zhao/VPD)**|
|**2023-03-27**|**PolyFormer: Referring Image Segmentation as Sequential Polygon Generation**|Jiang Liu et.al.|[2302.07387](http://arxiv.org/abs/2302.07387)|**[link](https://github.com/amazon-science/polygon-transformer)**|
|**2023-03-22**|**Linguistic Query-Guided Mask Generation for Referring Image Segmentation**|Zhichao Wei et.al.|[2301.06429](http://arxiv.org/abs/2301.06429)|null|
|**2022-12-27**|**Position-Aware Contrastive Alignment for Referring Image Segmentation**|Bo Chen et.al.|[2212.13419](http://arxiv.org/abs/2212.13419)|null|
|**2022-12-17**|**Fully and Weakly Supervised Referring Expression Segmentation with End-to-End Learning**|Hui Li et.al.|[2212.10278](http://arxiv.org/abs/2212.10278)|null|
|**2022-12-04**|**CoupAlign: Coupling Word-Pixel with Sentence-Mask Alignments for Referring Image Segmentation**|Zicheng Zhang et.al.|[2212.01769](http://arxiv.org/abs/2212.01769)|null|
|**2022-11-15**|**A Unified Mutual Supervision Framework for Referring Expression Segmentation and Generation**|Shijia Huang et.al.|[2211.07919](http://arxiv.org/abs/2211.07919)|null|
|**2022-09-21**|**Exploring Modulated Detection Transformer as a Tool for Action Recognition in Videos**|Tomás Crisol et.al.|[2209.10126](http://arxiv.org/abs/2209.10126)|**[link](https://github.com/bhi-research/ava_mdetr)**|
|**2023-07-23**|**Towards Robust Referring Image Segmentation**|Jianzong Wu et.al.|[2209.09554](http://arxiv.org/abs/2209.09554)|**[link](https://github.com/jianzongwu/robust-ref-seg)**|
|**2022-05-12**|**Weakly-supervised segmentation of referring expressions**|Robin Strudel et.al.|[2205.04725](http://arxiv.org/abs/2205.04725)|null|
|**2022-03-31**|**ReSTR: Convolution-free Referring Image Segmentation Using Transformers**|Namyup Kim et.al.|[2203.16768](http://arxiv.org/abs/2203.16768)|null|
|**2021-12-24**|**Grounding Linguistic Commands to Navigable Regions**|Nivedita Rufus et.al.|[2112.13031](http://arxiv.org/abs/2112.13031)|**[link](https://github.com/kanji95/Talk2car-Refseg)**|
|**2022-03-30**|**Image Segmentation Using Text and Image Prompts**|Timo Lüddecke et.al.|[2112.10003](http://arxiv.org/abs/2112.10003)|**[link](https://github.com/timojl/clipseg)**|
|**2022-04-05**|**LAVT: Language-Aware Vision Transformer for Referring Image Segmentation**|Zhao Yang et.al.|[2112.02244](http://arxiv.org/abs/2112.02244)|**[link](https://github.com/yz93/lavt-ris)**|
|**2022-03-14**|**CRIS: CLIP-Driven Referring Image Segmentation**|Zhaoqing Wang et.al.|[2111.15174](http://arxiv.org/abs/2111.15174)|**[link](https://github.com/DerrickWang005/CRIS.pytorch)**|
|**2021-11-25**|**MaIL: A Unified Mask-Image-Language Trimodal Network for Referring Image Segmentation**|Zizhang Li et.al.|[2111.10747](http://arxiv.org/abs/2111.10747)|null|
|**2021-10-09**|**Two-stage Visual Cues Enhancement Network for Referring Image Segmentation**|Yang Jiao et.al.|[2110.04435](http://arxiv.org/abs/2110.04435)|**[link](https://github.com/sxjyjay/tv-net)**|
|**2021-06-16**|**CMF: Cascaded Multi-model Fusion for Referring Image Segmentation**|Jianhua Yang et.al.|[2106.08617](http://arxiv.org/abs/2106.08617)|**[link](https://github.com/jianhua2022/CMF-Refseg)**|
|**2021-05-15**|**Cross-Modal Progressive Comprehension for Referring Segmentation**|Si Liu et.al.|[2105.07175](http://arxiv.org/abs/2105.07175)|**[link](https://github.com/spyflying/CMPC-Refseg)**|
|**2021-05-05**|**Encoder Fusion Network with Co-Attention Embedding for Referring Image Segmentation**|Guang Feng et.al.|[2105.01839](http://arxiv.org/abs/2105.01839)|null|
|**2022-08-14**|**Comprehensive Multi-Modal Interactions for Referring Image Segmentation**|Kanishk Jain et.al.|[2104.10412](http://arxiv.org/abs/2104.10412)|**[link](https://github.com/kanji95/SHNET)**|
|**2021-03-30**|**Locate then Segment: A Strong Pipeline for Referring Image Segmentation**|Ya Jing et.al.|[2103.16284](http://arxiv.org/abs/2103.16284)|null|
|**2021-04-14**|**OCID-Ref: A 3D Robotic Dataset with Embodied Language for Clutter Scene Grounding**|Ke-Jyun Wang et.al.|[2103.07679](http://arxiv.org/abs/2103.07679)|**[link](https://github.com/lluma/OCID-Ref)**|
|**2020-10-05**|**Linguistic Structure Guided Context Modeling for Referring Image Segmentation**|Tianrui Hui et.al.|[2010.00515](http://arxiv.org/abs/2010.00515)|**[link](https://github.com/spyflying/LSCM-Refseg)**|
|**2020-10-01**|**Referring Image Segmentation via Cross-Modal Progressive Comprehension**|Shaofei Huang et.al.|[2010.00514](http://arxiv.org/abs/2010.00514)|**[link](https://github.com/spyflying/CMPC-Refseg)**|
|**2022-06-23**|**Modulating Bottom-Up and Top-Down Visual Processing via Language-Conditional Filters**|İlker Kesen et.al.|[2003.12739](http://arxiv.org/abs/2003.12739)|**[link](https://github.com/ilkerkesen/bvpr)**|
|**2020-01-30**|**Dual Convolutional LSTM Network for Referring Image Segmentation**|Linwei Ye et.al.|[2001.11561](http://arxiv.org/abs/2001.11561)|null|
|**2019-04-09**|**Cross-Modal Self-Attention Network for Referring Image Segmentation**|Linwei Ye et.al.|[1904.04745](http://arxiv.org/abs/1904.04745)|null|
|**2019-04-06**|**CLEVR-Ref+: Diagnosing Visual Reasoning with Referring Expressions**|Runtao Liu et.al.|[1901.00850](http://arxiv.org/abs/1901.00850)|null|
|**2017-08-04**|**Recurrent Multimodal Interaction for Referring Image Segmentation**|Chenxi Liu et.al.|[1703.07939](http://arxiv.org/abs/1703.07939)|**[link](https://github.com/chenxi116/TF-phrasecut-public)**|

<p align=right>(<a href=#updated-on-20250511>back to top</a>)</p>

## RVOS

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-04-18**|**Few-Shot Referring Video Single- and Multi-Object Segmentation via Cross-Modal Affinity with Instance Sequence Matching**|Heng Liu et.al.|[2504.13710](http://arxiv.org/abs/2504.13710)|**[link](https://github.com/hengliusky/few_shot_rvos)**|
|**2025-04-10**|**GLUS: Global-Local Reasoning Unified into A Single Large Language Model for Video Segmentation**|Lang Lin et.al.|[2504.07962](http://arxiv.org/abs/2504.07962)|null|
|**2025-04-07**|**The 1st Solution for 4th PVUW MeViS Challenge: Unleashing the Potential of Large Multimodal Models for Referring Video Segmentation**|Hao Fang et.al.|[2504.05178](http://arxiv.org/abs/2504.05178)|null|
|**2025-04-01**|**4th PVUW MeViS 3rd Place Report: Sa2VA**|Haobo Yuan et.al.|[2504.00476](http://arxiv.org/abs/2504.00476)|**[link](https://github.com/magic-research/Sa2VA)**|
|**2025-03-30**|**ReferDINO-Plus: 2nd Solution for 4th PVUW MeViS Challenge at CVPR 2025**|Tianming Liang et.al.|[2503.23509](http://arxiv.org/abs/2503.23509)|**[link](https://github.com/isee-laboratory/referdino-plus)**|
|**2025-03-05**|**Find First, Track Next: Decoupling Identification and Propagation in Referring Video Object Segmentation**|Suhwan Cho et.al.|[2503.03492](http://arxiv.org/abs/2503.03492)|**[link](https://github.com/suhwan-cho/FindTrack)**|
|**2025-04-12**|**Text-Promptable Propagation for Referring Medical Image Sequence Segmentation**|Runtian Yuan et.al.|[2502.11093](http://arxiv.org/abs/2502.11093)|null|
|**2025-01-24**|**ReferDINO: Referring Video Object Segmentation with Visual Grounding Foundations**|Tianming Liang et.al.|[2501.14607](http://arxiv.org/abs/2501.14607)|null|
|**2025-03-10**|**MPG-SAM 2: Adapting SAM 2 with Mask Priors and Global Context for Referring Video Object Segmentation**|Fu Rong et.al.|[2501.13667](http://arxiv.org/abs/2501.13667)|null|
|**2025-01-15**|**Multi-Context Temporal Consistent Modeling for Referring Video Object Segmentation**|Sun-Hyuk Choi et.al.|[2501.04939](http://arxiv.org/abs/2501.04939)|**[link](https://github.com/choi58/mtcm)**|
|**2025-02-13**|**Sa2VA: Marrying SAM2 with LLaVA for Dense Grounded Understanding of Images and Videos**|Haobo Yuan et.al.|[2501.04001](http://arxiv.org/abs/2501.04001)|**[link](https://github.com/magic-research/Sa2VA)**|
|**2025-03-26**|**Referring Video Object Segmentation via Language-aligned Track Selection**|Seongchan Kim et.al.|[2412.01136](http://arxiv.org/abs/2412.01136)|**[link](https://github.com/cvlab-kaist/SOLA)**|
|**2025-03-25**|**SAMWISE: Infusing Wisdom in SAM2 for Text-Driven Video Segmentation**|Claudia Cuttano et.al.|[2411.17646](http://arxiv.org/abs/2411.17646)|**[link](https://github.com/claudiacuttano/samwise)**|
|**2024-09-09**|**LSVOS Challenge Report: Large-scale Complex and Long Video Object Segmentation**|Henghui Ding et.al.|[2409.05847](http://arxiv.org/abs/2409.05847)|null|
|**2024-08-22**|**The 2nd Solution for LSVOS Challenge RVOS Track: Spatial-temporal Refinement for Consistent Semantic Segmentation**|Tuyen Tran et.al.|[2408.12447](http://arxiv.org/abs/2408.12447)|null|
|**2024-08-20**|**The Instance-centric Transformer for the RVOS Track of LSVOS Challenge: 3rd Place Solution**|Bin Cao et.al.|[2408.10541](http://arxiv.org/abs/2408.10541)|null|
|**2024-08-24**|**UNINEXT-Cutie: The 1st Solution for LSVOS Challenge RVOS Track**|Hao Fang et.al.|[2408.10129](http://arxiv.org/abs/2408.10129)|null|
|**2024-07-10**|**ActionVOS: Actions as Prompts for Video Object Segmentation**|Liangyang Ouyang et.al.|[2407.07402](http://arxiv.org/abs/2407.07402)|**[link](https://github.com/ut-vision/actionvos)**|
|**2024-06-20**|**2nd Place Solution for MeViS Track in CVPR 2024 PVUW Workshop: Motion Expression guided Video Segmentation**|Bin Cao et.al.|[2406.13939](http://arxiv.org/abs/2406.13939)|null|
|**2024-06-23**|**GroPrompt: Efficient Grounded Prompting and Adaptation for Referring Video Object Segmentation**|Ci-Siang Lin et.al.|[2406.12834](http://arxiv.org/abs/2406.12834)|null|
|**2024-06-11**|**1st Place Solution for MeViS Track in CVPR 2024 PVUW Workshop: Motion Expression guided Video Segmentation**|Mingqi Gao et.al.|[2406.07043](http://arxiv.org/abs/2406.07043)|**[link](https://github.com/tapall-ai/mevis_track_solution_2024)**|
|**2024-06-07**|**3rd Place Solution for MeViS Track in CVPR 2024 PVUW workshop: Motion Expression guided Video Segmentation**|Feiyu Pan et.al.|[2406.04842](http://arxiv.org/abs/2406.04842)|null|
|**2024-09-22**|**Harnessing Vision-Language Pretrained Models with Temporal-Aware Adaptation for Referring Video Object Segmentation**|Zikun Zhou et.al.|[2405.10610](http://arxiv.org/abs/2405.10610)|null|
|**2024-10-11**|**Temporally Consistent Referring Video Object Segmentation with Hybrid Memory**|Bo Miao et.al.|[2403.19407](http://arxiv.org/abs/2403.19407)|**[link](https://github.com/bo-miao/HTR)**|
|**2024-07-06**|**Exploring Pre-trained Text-to-Video Diffusion Models for Referring Video Object Segmentation**|Zixin Zhu et.al.|[2403.12042](http://arxiv.org/abs/2403.12042)|**[link](https://github.com/buxiangzhiren/vd-it)**|
|**2024-01-01**|**1st Place Solution for 5th LSVOS Challenge: Referring Video Object Segmentation**|Zhuoyan Luo et.al.|[2401.00663](http://arxiv.org/abs/2401.00663)|**[link](https://github.com/robertluo1/iccv2023_rvos_challenge)**|
|**2023-12-29**|**Tracking with Human-Intent Reasoning**|Jiawen Zhu et.al.|[2312.17448](http://arxiv.org/abs/2312.17448)|**[link](https://github.com/jiawen-zhu/trackgpt)**|
|**2023-12-25**|**UniRef++: Segment Every Reference Object in Spatial and Temporal Spaces**|Jiannan Wu et.al.|[2312.15715](http://arxiv.org/abs/2312.15715)|**[link](https://github.com/foundationvision/uniref)**|
|**2023-09-21**|**Fully Transformer-Equipped Architecture for End-to-End Referring Video Object Segmentation**|Ping Li et.al.|[2309.11933](http://arxiv.org/abs/2309.11933)|null|
|**2023-09-07**|**Temporal Collection and Distribution for Referring Video Object Segmentation**|Jiajin Tang et.al.|[2309.03473](http://arxiv.org/abs/2309.03473)|null|
|**2023-09-05**|**Learning Cross-Modal Affinity for Referring Video Object Segmentation Targeting Limited Samples**|Guanghui Li et.al.|[2309.02041](http://arxiv.org/abs/2309.02041)|**[link](https://github.com/hengliusky/few_shot_rvos)**|
|**2023-08-16**|**MeViS: A Large-scale Benchmark for Video Segmentation with Motion Expressions**|Henghui Ding et.al.|[2308.08544](http://arxiv.org/abs/2308.08544)|**[link](https://github.com/henghuiding/MeViS)**|
|**2025-01-17**|**Expression Prompt Collaboration Transformer for Universal Referring Video Object Segmentation**|Jiajun Chen et.al.|[2308.04162](http://arxiv.org/abs/2308.04162)|**[link](https://github.com/lab206/epcformer)**|
|**2023-12-15**|**Learning Referring Video Object Segmentation from Weak Annotation**|Wangbo Zhao et.al.|[2308.02162](http://arxiv.org/abs/2308.02162)|null|
|**2023-07-25**|**Spectrum-guided Multi-granularity Referring Video Object Segmentation**|Bo Miao et.al.|[2307.13537](http://arxiv.org/abs/2307.13537)|**[link](https://github.com/bo-miao/sgmg)**|
|**2023-07-18**|**OnlineRefer: A Simple Online Baseline for Referring Video Object Segmentation**|Dongming Wu et.al.|[2307.09356](http://arxiv.org/abs/2307.09356)|**[link](https://github.com/wudongming97/onlinerefer)**|
|**2024-09-03**|**RefSAM: Efficiently Adapting Segmenting Anything Model for Referring Video Object Segmentation**|Yonglin Li et.al.|[2307.00997](http://arxiv.org/abs/2307.00997)|**[link](https://github.com/lancasterli/refsam)**|
|**2023-09-17**|**Bidirectional Correlation-Driven Inter-Frame Interaction Transformer for Referring Video Object Segmentation**|Meng Lan et.al.|[2307.00536](http://arxiv.org/abs/2307.00536)|null|
|**2024-04-02**|**LoSh: Long-Short Text Joint Prediction Network for Referring Video Object Segmentation**|Linfeng Yuan et.al.|[2306.08736](http://arxiv.org/abs/2306.08736)|**[link](https://github.com/linfengyuan1997/losh)**|
|**2023-05-26**|**SOC: Semantic-Assisted Object Cluster for Referring Video Object Segmentation**|Zhuoyan Luo et.al.|[2305.17011](http://arxiv.org/abs/2305.17011)|**[link](https://github.com/RobertLuo1/NeurIPS2023_SOC)**|
|**2023-12-12**|**Referred by Multi-Modality: A Unified Temporal Transformer for Video Object Segmentation**|Shilin Yan et.al.|[2305.16318](http://arxiv.org/abs/2305.16318)|**[link](https://github.com/opengvlab/mutr)**|
|**2022-12-27**|**1st Place Solution for YouTubeVOS Challenge 2022: Referring Video Object Segmentation**|Zhiwei Hu et.al.|[2212.14679](http://arxiv.org/abs/2212.14679)|**[link](https://github.com/zhiweihhh/cvpr2022-rvos-challenge)**|
|**2022-07-26**|**Multi-Attention Network for Compressed Video Referring Object Segmentation**|Weidong Chen et.al.|[2207.12622](http://arxiv.org/abs/2207.12622)|**[link](https://github.com/dexianghong/manet)**|
|**2023-08-18**|**Towards Robust Referring Video Object Segmentation with Cyclic Relational Consensus**|Xiang Li et.al.|[2207.01203](http://arxiv.org/abs/2207.01203)|**[link](https://github.com/lxa9867/R2VOS)**|
|**2022-06-24**|**The Second Place Solution for The 4th Large-scale Video Object Segmentation Challenge--Track 3: Referring Video Object Segmentation**|Leilei Cao et.al.|[2206.12035](http://arxiv.org/abs/2206.12035)|null|
|**2022-06-08**|**Language-Bridged Spatial-Temporal Interaction for Referring Video Object Segmentation**|Zihan Ding et.al.|[2206.03789](http://arxiv.org/abs/2206.03789)|**[link](https://github.com/dzh19990407/lbdt)**|
|**2024-01-19**|**Local-Global Context Aware Transformer for Language-Guided Video Segmentation**|Chen Liang et.al.|[2203.09773](http://arxiv.org/abs/2203.09773)|**[link](https://github.com/leonnnop/locater)**|
|**2022-03-13**|**Language as Queries for Referring Video Object Segmentation**|Jiannan Wu et.al.|[2201.00487](http://arxiv.org/abs/2201.00487)|**[link](https://github.com/wjn922/referformer)**|
|**2022-04-03**|**End-to-End Referring Video Object Segmentation with Multimodal Transformers**|Adam Botach et.al.|[2111.14821](http://arxiv.org/abs/2111.14821)|**[link](https://github.com/mttr2021/MTTR)**|
|**2024-01-19**|**Rethinking Cross-modal Interaction from a Top-down Perspective for Referring Video Object Segmentation**|Chen Liang et.al.|[2106.01061](http://arxiv.org/abs/2106.01061)|null|

<p align=right>(<a href=#updated-on-20250511>back to top</a>)</p>

## RVOT

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2024-03-29**|**Elysium: Exploring Object-level Perception in Videos via MLLM**|Han Wang et.al.|[2403.16558](http://arxiv.org/abs/2403.16558)|**[link](https://github.com/hon-wong/elysium)**|

<p align=right>(<a href=#updated-on-20250511>back to top</a>)</p>

## AVS

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-04-30**|**OpenAVS: Training-Free Open-Vocabulary Audio Visual Segmentation with Foundational Models**|Shengkai Chen et.al.|[2505.01448](http://arxiv.org/abs/2505.01448)|null|
|**2025-03-17**|**Robust Audio-Visual Segmentation via Audio-Guided Visual Convergent Alignment**|Chen Liu et.al.|[2503.12847](http://arxiv.org/abs/2503.12847)|null|
|**2025-03-17**|**Dynamic Derivation and Elimination: Audio Visual Segmentation with Enhanced Audio Semantics**|Chen Liu et.al.|[2503.12840](http://arxiv.org/abs/2503.12840)|null|
|**2025-02-22**|**Audio Visual Segmentation Through Text Embeddings**|Kyungbok Lee et.al.|[2502.16359](http://arxiv.org/abs/2502.16359)|null|
|**2025-02-20**|**Do Audio-Visual Segmentation Models Truly Segment Sounding Objects?**|Jia Li et.al.|[2502.00358](http://arxiv.org/abs/2502.00358)|null|
|**2025-01-14**|**AVS-Mamba: Exploring Temporal and Multi-modal Mamba for Audio-Visual Segmentation**|Sitong Gong et.al.|[2501.07810](http://arxiv.org/abs/2501.07810)|**[link](https://github.com/sitonggong/avs-mamba)**|
|**2024-12-17**|**Multimodal Class-aware Semantic Enhancement Network for Audio-Visual Video Parsing**|Pengcheng Zhao et.al.|[2412.11248](http://arxiv.org/abs/2412.11248)|null|
|**2024-12-11**|**Collaborative Hybrid Propagator for Temporal Misalignment in Audio-Visual Segmentation**|Kexin Li et.al.|[2412.08161](http://arxiv.org/abs/2412.08161)|null|
|**2024-11-04**|**3D Audio-Visual Segmentation**|Artem Sokolov et.al.|[2411.02236](http://arxiv.org/abs/2411.02236)|null|
|**2024-08-03**|**AVESFormer: Efficient Transformer Design for Real-Time Audio-Visual Segmentation**|Zili Wang et.al.|[2408.01708](http://arxiv.org/abs/2408.01708)|**[link](https://github.com/markxcloud/avesformer)**|
|**2024-07-23**|**Unveiling and Mitigating Bias in Audio Visual Segmentation**|Peiwen Sun et.al.|[2407.16638](http://arxiv.org/abs/2407.16638)|null|
|**2024-09-12**|**Stepping Stones: A Progressive Training Strategy for Audio-Visual Semantic Segmentation**|Juncheng Ma et.al.|[2407.11820](http://arxiv.org/abs/2407.11820)|**[link](https://github.com/GeWu-Lab/Stepping-Stones)**|
|**2024-07-15**|**Ref-AVS: Refer and Segment Objects in Audio-Visual Scenes**|Yaoting Wang et.al.|[2407.10957](http://arxiv.org/abs/2407.10957)|null|
|**2024-07-15**|**Can Textual Semantics Mitigate Sounding Object Segmentation Preference?**|Yaoting Wang et.al.|[2407.10947](http://arxiv.org/abs/2407.10947)|**[link](https://github.com/gewu-lab/sounding-object-segmentation-preference)**|
|**2024-07-11**|**Label-anticipated Event Disentanglement for Audio-Visual Video Parsing**|Jinxing Zhou et.al.|[2407.08126](http://arxiv.org/abs/2407.08126)|null|
|**2024-09-29**|**CPM: Class-conditional Prompting Machine for Audio-visual Segmentation**|Yuanhong Chen et.al.|[2407.05358](http://arxiv.org/abs/2407.05358)|null|
|**2024-07-03**|**SAVE: Segment Audio-Visual Easy way using Segment Anything Model**|Khanh-Binh Nguyen et.al.|[2407.02004](http://arxiv.org/abs/2407.02004)|null|
|**2024-06-10**|**Extending Segment Anything Model into Auditory and Temporal Dimensions for Audio-Visual Segmentation**|Juhyeong Seon et.al.|[2406.06163](http://arxiv.org/abs/2406.06163)|**[link](https://github.com/Sunjuhyeong/SAM_STBAVA)**|
|**2025-02-10**|**Progressive Confident Masking Attention Network for Audio-Visual Segmentation**|Yuxuan Wang et.al.|[2406.02345](http://arxiv.org/abs/2406.02345)|**[link](https://github.com/prettyplate/pcmanet)**|
|**2024-03-21**|**Unsupervised Audio-Visual Segmentation with Modality Alignment**|Swapnil Bhosale et.al.|[2403.14203](http://arxiv.org/abs/2403.14203)|null|
|**2024-03-17**|**Audio-Visual Segmentation via Unlabeled Frame Exploitation**|Jinxiang Liu et.al.|[2403.11074](http://arxiv.org/abs/2403.11074)|null|
|**2024-02-06**|**Bootstrapping Audio-Visual Segmentation by Strengthening Audio Cues**|Tianxiang Chen et.al.|[2402.02327](http://arxiv.org/abs/2402.02327)|null|
|**2024-04-07**|**Cooperation Does Matter: Exploring Multi-Order Bilateral Relations for Audio-Visual Segmentation**|Qi Yang et.al.|[2312.06462](http://arxiv.org/abs/2312.06462)|**[link](https://github.com/yannqi/COMBO-AVS)**|
|**2023-12-02**|**Unveiling the Power of Audio-Visual Early Fusion Transformers with Dense Interactions through Masked Modeling**|Shentong Mo et.al.|[2312.01017](http://arxiv.org/abs/2312.01017)|**[link](https://github.com/stonemo/deepavfusion)**|
|**2023-11-25**|**Weakly-Supervised Audio-Visual Segmentation**|Shentong Mo et.al.|[2311.15080](http://arxiv.org/abs/2311.15080)|null|
|**2023-10-12**|**Multimodal Variational Auto-encoder based Audio-Visual Segmentation**|Yuxin Mao et.al.|[2310.08303](http://arxiv.org/abs/2310.08303)|**[link](https://github.com/opennlplab/mmvae-avs)**|
|**2024-07-17**|**Cross-modal Cognitive Consensus guided Audio-Visual Segmentation**|Zhaofeng Shi et.al.|[2310.06259](http://arxiv.org/abs/2310.06259)|**[link](https://github.com/zhaofengshi/avs-c3n)**|
|**2023-09-18**|**Discovering Sounding Objects by Audio Queries for Audio Visual Segmentation**|Shaofei Huang et.al.|[2309.09501](http://arxiv.org/abs/2309.09501)|null|
|**2023-09-13**|**Leveraging Foundation models for Unsupervised Audio-Visual Segmentation**|Swapnil Bhosale et.al.|[2309.06728](http://arxiv.org/abs/2309.06728)|null|
|**2023-08-20**|**BAVS: Bootstrapping Audio-Visual Segmentation by Integrating Foundation Knowledge**|Chen Liu et.al.|[2308.10175](http://arxiv.org/abs/2308.10175)|null|
|**2023-12-19**|**Improving Audio-Visual Segmentation with Bidirectional Generation**|Dawei Hao et.al.|[2308.08288](http://arxiv.org/abs/2308.08288)|**[link](https://github.com/opennlplab/avs-bidirectional)**|
|**2023-08-10**|**Progressive Spatio-temporal Perception for Audio-Visual Question Answering**|Guangyao Li et.al.|[2308.05421](http://arxiv.org/abs/2308.05421)|**[link](https://github.com/gewu-lab/pstp-net)**|
|**2023-08-01**|**Audio-Visual Segmentation by Exploring Cross-Modal Mutual Semantics**|Chen Liu et.al.|[2307.16620](http://arxiv.org/abs/2307.16620)|null|
|**2023-07-31**|**Contrastive Conditional Latent Diffusion for Audio-visual Segmentation**|Yuxin Mao et.al.|[2307.16579](http://arxiv.org/abs/2307.16579)|null|
|**2023-07-25**|**Audio-aware Query-enhanced Transformer for Audio-Visual Segmentation**|Jinxiang Liu et.al.|[2307.13236](http://arxiv.org/abs/2307.13236)|null|
|**2023-12-18**|**AVSegFormer: Audio-Visual Segmentation with Transformer**|Shengyi Gao et.al.|[2307.01146](http://arxiv.org/abs/2307.01146)|**[link](https://github.com/vvvb-github/avsegformer)**|
|**2023-10-07**|**Annotation-free Audio-Visual Segmentation**|Jinxiang Liu et.al.|[2305.11019](http://arxiv.org/abs/2305.11019)|null|
|**2023-12-26**|**Transavs: End-To-End Audio-Visual Segmentation With Transformer**|Yuhang Ling et.al.|[2305.07223](http://arxiv.org/abs/2305.07223)|null|
|**2023-05-03**|**AV-SAM: Segment Anything Model Meets Audio-Visual Localization and Segmentation**|Shentong Mo et.al.|[2305.01836](http://arxiv.org/abs/2305.01836)|null|
|**2024-09-17**|**MED-VT++: Unifying Multimodal Learning with a Multiscale Encoder-Decoder Video Transformer**|Rezaul Karim et.al.|[2304.05930](http://arxiv.org/abs/2304.05930)|null|
|**2024-08-14**|**Unraveling Instance Associations: A Closer Look for Audio-Visual Segmentation**|Yuanhong Chen et.al.|[2304.02970](http://arxiv.org/abs/2304.02970)|**[link](https://github.com/cyh-0/CAVP)**|
|**2023-01-30**|**Audio-Visual Segmentation with Semantics**|Jinxing Zhou et.al.|[2301.13190](http://arxiv.org/abs/2301.13190)|**[link](https://github.com/opennlplab/avsbench)**|
|**2023-02-17**|**Audio-Visual Segmentation**|Jinxing Zhou et.al.|[2207.05042](http://arxiv.org/abs/2207.05042)|**[link](https://github.com/opennlplab/avsbench)**|
|**2021-04-05**|**Positive Sample Propagation along the Audio-Visual Event Line**|Jinxing Zhou et.al.|[2104.00239](http://arxiv.org/abs/2104.00239)|**[link](https://github.com/jasongief/PSP_CVPR_2021)**|

<p align=right>(<a href=#updated-on-20250511>back to top</a>)</p>

## 3D-RES

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-04-17**|**3DResT: A Strong Baseline for Semi-Supervised 3D Referring Expression Segmentation**|Wenxin Chen et.al.|[2504.12599](http://arxiv.org/abs/2504.12599)|null|
|**2025-01-09**|**IPDN: Image-enhanced Prompt Decoding Network for 3D Referring Expression Segmentation**|Qi Chen et.al.|[2501.04995](http://arxiv.org/abs/2501.04995)|**[link](https://github.com/80chen86/ipdn)**|
|**2024-12-22**|**RG-SAN: Rule-Guided Spatial Awareness Network for End-to-End 3D Referring Expression Segmentation**|Changli Wu et.al.|[2412.02402](http://arxiv.org/abs/2412.02402)|**[link](https://github.com/sosppxo/rg-san)**|
|**2024-07-31**|**3D-GRES: Generalized 3D Referring Expression Segmentation**|Changli Wu et.al.|[2407.20664](http://arxiv.org/abs/2407.20664)|**[link](https://github.com/sosppxo/MDIN)**|
|**2023-08-31**|**3D-STMN: Dependency-Driven Superpoint-Text Matching Network for End-to-End 3D Referring Expression Segmentation**|Changli Wu et.al.|[2308.16632](http://arxiv.org/abs/2308.16632)|**[link](https://github.com/sosppxo/3d-stmn)**|

<p align=right>(<a href=#updated-on-20250511>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

