[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2025.08.06
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#res>RES</a></li>
    <li><a href=#rvos>RVOS</a></li>
    <li><a href=#rvot>RVOT</a></li>
    <li><a href=#avs>AVS</a></li>
    <li><a href=#3d-res>3D-RES</a></li>
    <li><a href=#poster-generation>Poster Generation</a></li>
    <li><a href=#graphic-design-generation>Graphic Design Generation</a></li>
    <li><a href=#layout-generation>Layout Generation</a></li>
  </ol>
</details>

## RES

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-07-22**|**Advancing Visual Large Language Model for Multi-granular Versatile Perception**|Wentao Xiang et.al.|[2507.16213](http://arxiv.org/abs/2507.16213)|null|
|**2025-07-02**|**DeRIS: Decoupling Perception and Cognition for Enhanced Referring Image Segmentation through Loopback Synergy**|Ming Dai et.al.|[2507.01738](http://arxiv.org/abs/2507.01738)|null|
|**2025-06-28**|**Mask-aware Text-to-Image Retrieval: Referring Expression Segmentation Meets Cross-modal Retrieval**|Li-Cheng Shen et.al.|[2506.22864](http://arxiv.org/abs/2506.22864)|null|
|**2025-06-19**|**MBA: Multimodal Bidirectional Attack for Referring Expression Segmentation Models**|Xingbai Chen et.al.|[2506.16157](http://arxiv.org/abs/2506.16157)|null|
|**2025-06-11**|**ELBO-T2IAlign: A Generic ELBO-Based Method for Calibrating Pixel-level Text-Image Alignment in Diffusion Models**|Qin Zhou et.al.|[2506.09740](http://arxiv.org/abs/2506.09740)|null|
|**2025-06-05**|**Refer to Anything with Vision-Language Prompts**|Shengcao Cao et.al.|[2506.05342](http://arxiv.org/abs/2506.05342)|null|
|**2025-05-25**|**Deformable Attentive Visual Enhancement for Referring Segmentation Using Vision-Language Model**|Alaa Dalaq et.al.|[2505.19242](http://arxiv.org/abs/2505.19242)|null|
|**2025-06-02**|**RemoteSAM: Towards Segment Anything for Earth Observation**|Liang Yao et.al.|[2505.18022](http://arxiv.org/abs/2505.18022)|**[link](https://github.com/1e12Leon/RemoteSAM)**|
|**2025-05-23**|**SynRES: Towards Referring Expression Segmentation in the Wild via Synthetic Data**|Dong-Hee Kim et.al.|[2505.17695](http://arxiv.org/abs/2505.17695)|null|
|**2025-05-03**|**RESAnything: Attribute Prompting for Arbitrary Referring Segmentation**|Ruiqi Wang et.al.|[2505.02867](http://arxiv.org/abs/2505.02867)|null|
|**2025-05-28**|**Progressive Language-guided Visual Learning for Multi-Task Visual Grounding**|Jingchao Wang et.al.|[2504.16145](http://arxiv.org/abs/2504.16145)|null|
|**2025-05-01**|**LGD: Leveraging Generative Descriptions for Zero-Shot Referring Image Segmentation**|Jiachen Li et.al.|[2504.14467](http://arxiv.org/abs/2504.14467)|null|
|**2025-04-17**|**3DResT: A Strong Baseline for Semi-Supervised 3D Referring Expression Segmentation**|Wenxin Chen et.al.|[2504.12599](http://arxiv.org/abs/2504.12599)|null|
|**2025-04-15**|**Aligning Generative Denoising with Discriminative Objectives Unleashes Diffusion for Visual Perception**|Ziqi Pang et.al.|[2504.11457](http://arxiv.org/abs/2504.11457)|**[link](https://github.com/ziqipang/addp)**|
|**2025-04-02**|**Towards Unified Referring Expression Segmentation Across Omni-Level Visual Target Granularities**|Jing Liu et.al.|[2504.01954](http://arxiv.org/abs/2504.01954)|null|
|**2025-04-01**|**Hybrid Global-Local Representation with Augmented Spatial Guidance for Zero-Shot Referring Image Segmentation**|Ting Liu et.al.|[2504.00356](http://arxiv.org/abs/2504.00356)|**[link](https://github.com/fhgyuanshen/hybridgl)**|
|**2025-03-17**|**Scale Efficient Training for Large Datasets**|Qing Zhou et.al.|[2503.13385](http://arxiv.org/abs/2503.13385)|**[link](https://github.com/mrazhou/seta)**|
|**2025-07-15**|**GroundingSuite: Measuring Complex Multi-Granular Pixel Grounding**|Rui Hu et.al.|[2503.10596](http://arxiv.org/abs/2503.10596)|**[link](https://github.com/hustvl/groundingsuite)**|
|**2025-03-02**|**IteRPrimE: Zero-shot Referring Image Segmentation with Iterative Grad-CAM Refinement and Primary Word Emphasis**|Yuji Wang et.al.|[2503.00936](http://arxiv.org/abs/2503.00936)|**[link](https://github.com/VoyageWang/IteRPrimE)**|
|**2025-02-28**|**AeroReformer: Aerial Referring Transformer for UAV-based Referring Image Segmentation**|Rui Li et.al.|[2502.16680](http://arxiv.org/abs/2502.16680)|**[link](https://github.com/lironui/aeroreformer)**|
|**2025-02-23**|**PixFoundation: Are We Heading in the Right Direction with Pixel-level Vision Foundation Models?**|Mennatullah Siam et.al.|[2502.04192](http://arxiv.org/abs/2502.04192)|**[link](https://github.com/msiam/pixfoundation)**|
|**2025-03-31**|**Know "No'' Better: A Data-Driven Approach for Enhancing Negation Awareness in CLIP**|Junsung Park et.al.|[2501.10913](http://arxiv.org/abs/2501.10913)|null|
|**2025-01-15**|**Densely Connected Parameter-Efficient Tuning for Referring Image Segmentation**|Jiaqi Huang et.al.|[2501.08580](http://arxiv.org/abs/2501.08580)|**[link](https://github.com/jiaqihuang01/detris)**|
|**2025-01-12**|**Multi-task Visual Grounding with Coarse-to-Fine Consistency Constraints**|Ming Dai et.al.|[2501.06710](http://arxiv.org/abs/2501.06710)|**[link](https://github.com/dmmm1997/c3vg)**|
|**2025-01-09**|**IPDN: Image-enhanced Prompt Decoding Network for 3D Referring Expression Segmentation**|Qi Chen et.al.|[2501.04995](http://arxiv.org/abs/2501.04995)|**[link](https://github.com/80chen86/ipdn)**|
|**2025-01-02**|**Hierarchical Alignment-enhanced Adaptive Grounding Network for Generalized Referring Expression Comprehension**|Yaxian Wang et.al.|[2501.01416](http://arxiv.org/abs/2501.01416)|null|
|**2024-12-14**|**Grasp What You Want: Embodied Dexterous Grasping System Driven by Your Voice**|Junliang Li et.al.|[2412.10694](http://arxiv.org/abs/2412.10694)|null|
|**2024-12-22**|**RG-SAN: Rule-Guided Spatial Awareness Network for End-to-End 3D Referring Expression Segmentation**|Changli Wu et.al.|[2412.02402](http://arxiv.org/abs/2412.02402)|**[link](https://github.com/sosppxo/rg-san)**|
|**2024-11-28**|**MaskRIS: Semantic Distortion-aware Data Augmentation for Referring Image Segmentation**|Minhyun Lee et.al.|[2411.19067](http://arxiv.org/abs/2411.19067)|**[link](https://github.com/naver-ai/maskris)**|
|**2024-11-22**|**Instance-Aware Generalized Referring Expression Segmentation**|E-Ro Nguyen et.al.|[2411.15087](http://arxiv.org/abs/2411.15087)|null|
|**2024-11-03**|**Finding NeMo: Negative-mined Mosaic Augmentation for Referring Image Segmentation**|Seongsu Ha et.al.|[2411.01494](http://arxiv.org/abs/2411.01494)|null|
|**2024-10-31**|**SegLLM: Multi-round Reasoning Segmentation**|XuDong Wang et.al.|[2410.18923](http://arxiv.org/abs/2410.18923)|null|
|**2025-02-17**|**Text4Seg: Reimagining Image Segmentation as Text Generation**|Mengcheng Lan et.al.|[2410.09855](http://arxiv.org/abs/2410.09855)|**[link](https://github.com/mc-lan/text4seg)**|
|**2024-12-04**|**Boosting Weakly-Supervised Referring Image Segmentation via Progressive Comprehension**|Zaiquan Yang et.al.|[2410.01544](http://arxiv.org/abs/2410.01544)|null|
|**2024-09-29**|**Fully Aligned Network for Referring Image Segmentation**|Yong Liu et.al.|[2409.19569](http://arxiv.org/abs/2409.19569)|null|
|**2025-02-07**|**A Parameter-Efficient Tuning Framework for Language-guided Object Grounding and Robot Grasping**|Houjian Yu et.al.|[2409.19457](http://arxiv.org/abs/2409.19457)|null|
|**2025-02-11**|**ADEPT: A Noninvasive Method for Determining Elastic Parameters of Valve Tissue**|Wensi Wu et.al.|[2409.19081](http://arxiv.org/abs/2409.19081)|null|
|**2025-02-18**|**PTQ4RIS: Post-Training Quantization for Referring Image Segmentation**|Xiaoyan Jiang et.al.|[2409.17020](http://arxiv.org/abs/2409.17020)|**[link](https://github.com/gugu511yy/ptq4ris)**|
|**2024-09-17**|**Robot Manipulation in Salient Vision through Referring Image Segmentation and Geometric Constraints**|Chen Jiang et.al.|[2409.11518](http://arxiv.org/abs/2409.11518)|null|
|**2024-12-14**|**SAM4MLLM: Enhance Multi-Modal Large Language Model for Referring Expression Segmentation**|Yi-Chia Chen et.al.|[2409.10542](http://arxiv.org/abs/2409.10542)|**[link](https://github.com/ai-application-and-integration-lab/sam4mllm)**|
|**2025-06-17**|**A Simple Baseline with Single-encoder for Referring Image Segmentation**|Seonghoon Yu et.al.|[2408.15521](http://arxiv.org/abs/2408.15521)|null|
|**2024-08-14**|**Cross-aware Early Fusion with Stage-divided Vision and Language Transformer Encoders for Referring Image Segmentation**|Yubin Cho et.al.|[2408.07539](http://arxiv.org/abs/2408.07539)|null|
|**2024-08-07**|**How Well Can Vision Language Models See Image Details?**|Chenhui Gou et.al.|[2408.03940](http://arxiv.org/abs/2408.03940)|null|
|**2024-07-31**|**3D-GRES: Generalized 3D Referring Expression Segmentation**|Changli Wu et.al.|[2407.20664](http://arxiv.org/abs/2407.20664)|**[link](https://github.com/sosppxo/MDIN)**|
|**2024-07-25**|**RefMask3D: Language-Guided Transformer for 3D Referring Segmentation**|Shuting He et.al.|[2407.18244](http://arxiv.org/abs/2407.18244)|**[link](https://github.com/heshuting555/refmask3d)**|
|**2024-07-17**|**Pseudo-RIS: Distinctive Pseudo-supervision Generation for Referring Image Segmentation**|Seonghoon Yu et.al.|[2407.07412](http://arxiv.org/abs/2407.07412)|**[link](https://github.com/seonghoon-yu/pseudo-ris)**|
|**2024-07-02**|**SafaRi:Adaptive Sequence Transformer for Weakly Supervised Referring Expression Segmentation**|Sayan Nag et.al.|[2407.02389](http://arxiv.org/abs/2407.02389)|null|
|**2025-03-10**|**EVF-SAM: Early Vision-Language Fusion for Text-Prompted Segment Anything Model**|Yuxuan Zhang et.al.|[2406.20076](http://arxiv.org/abs/2406.20076)|**[link](https://github.com/hustvl/evf-sam)**|
|**2025-04-11**|**F-LMM: Grounding Frozen Large Multimodal Models**|Size Wu et.al.|[2406.05821](http://arxiv.org/abs/2406.05821)|**[link](https://github.com/wusize/f-lmm)**|
|**2024-06-03**|**SAM as the Guide: Mastering Pseudo-Label Refinement in Semi-Supervised Referring Expression Segmentation**|Danni Yang et.al.|[2406.01451](http://arxiv.org/abs/2406.01451)|**[link](https://github.com/nini0919/semires)**|
|**2024-07-27**|**GOI: Find 3D Gaussians of Interest with an Optimizable Open-vocabulary Semantic-space Hyperplane**|Yansong Qu et.al.|[2405.17596](http://arxiv.org/abs/2405.17596)|null|
|**2024-11-25**|**CoHD: A Counting-Aware Hierarchical Decoding Framework for Generalized Referring Expression Segmentation**|Zhuoyan Luo et.al.|[2405.15658](http://arxiv.org/abs/2405.15658)|**[link](https://github.com/robertluo1/cohd)**|
|**2025-01-06**|**Bring Adaptive Binding Prototypes to Generalized Referring Expression Segmentation**|Weize Li et.al.|[2405.15169](http://arxiv.org/abs/2405.15169)|**[link](https://github.com/buptlwz/mabp)**|
|**2024-05-18**|**Fuse & Calibrate: A bi-directional Vision-Language Guided Framework for Referring Image Segmentation**|Yichen Yan et.al.|[2405.11205](http://arxiv.org/abs/2405.11205)|null|
|**2024-05-21**|**HARIS: Human-Like Attention for Reference Image Segmentation**|Mengxi Zhang et.al.|[2405.10707](http://arxiv.org/abs/2405.10707)|null|
|**2024-05-15**|**Spatial Semantic Recurrent Mining for Referring Image Segmentation**|Jiaxing Yang et.al.|[2405.09006](http://arxiv.org/abs/2405.09006)|null|
|**2024-04-18**|**Curriculum Point Prompting for Weakly-Supervised Referring Image Segmentation**|Qiyuan Dai et.al.|[2404.11998](http://arxiv.org/abs/2404.11998)|null|
|**2024-11-04**|**Vision-Aware Text Features in Referring Image Segmentation: From Object Understanding to Context Understanding**|Hai Nguyen-Truong et.al.|[2404.08590](http://arxiv.org/abs/2404.08590)|null|
|**2024-04-12**|**Calibration & Reconstruction: Deep Integrated Language for Referring Image Segmentation**|Yichen Yan et.al.|[2404.08281](http://arxiv.org/abs/2404.08281)|null|
|**2024-04-27**|**Deep Instruction Tuning for Segment Anything Model**|Xiaorui Huang et.al.|[2404.00650](http://arxiv.org/abs/2404.00650)|**[link](https://github.com/wysnzzzz/dit)**|
|**2024-07-25**|**ReMamber: Referring Image Segmentation with Mamba Twister**|Yuhuan Yang et.al.|[2403.17839](http://arxiv.org/abs/2403.17839)|**[link](https://github.com/yyh-rain-song/ReMamber)**|
|**2024-03-21**|**PSALM: Pixelwise SegmentAtion with Large Multi-Modal Model**|Zheng Zhang et.al.|[2403.14598](http://arxiv.org/abs/2403.14598)|**[link](https://github.com/zamling/psalm)**|
|**2024-06-27**|**Towards Alleviating Text-to-Image Retrieval Hallucination for CLIP in Zero-shot Learning**|Hanyao Wang et.al.|[2402.18400](http://arxiv.org/abs/2402.18400)|null|
|**2024-02-11**|**RESMatch: Referring Expression Segmentation in a Semi-Supervised Manner**|Ying Zang et.al.|[2402.05589](http://arxiv.org/abs/2402.05589)|null|
|**2024-02-04**|**Generalizable Entity Grounding via Assistance of Large Language Model**|Lu Qi et.al.|[2402.02555](http://arxiv.org/abs/2402.02555)|null|
|**2024-01-22**|**Collaborative Position Reasoning Network for Referring Image Segmentation**|Jianjian Cao et.al.|[2401.11775](http://arxiv.org/abs/2401.11775)|null|
|**2023-12-25**|**UniRef++: Segment Every Reference Object in Spatial and Temporal Spaces**|Jiannan Wu et.al.|[2312.15715](http://arxiv.org/abs/2312.15715)|**[link](https://github.com/foundationvision/uniref)**|
|**2024-04-02**|**Rotated Multi-Scale Interaction Network for Referring Remote Sensing Image Segmentation**|Sihan Liu et.al.|[2312.12470](http://arxiv.org/abs/2312.12470)|**[link](https://github.com/lsan2401/rmsin)**|
|**2024-03-25**|**Mask Grounding for Referring Image Segmentation**|Yong Xien Chng et.al.|[2312.12198](http://arxiv.org/abs/2312.12198)|**[link](https://github.com/yxchng/mask-grounding)**|
|**2024-03-21**|**GSVA: Generalized Segmentation via Multimodal Large Language Models**|Zhuofan Xia et.al.|[2312.10103](http://arxiv.org/abs/2312.10103)|**[link](https://github.com/leaplabthu/gsva)**|
|**2024-03-21**|**Unveiling Parts Beyond Objects:Towards Finer-Granularity Referring Expression Segmentation**|Wenxuan Wang et.al.|[2312.08007](http://arxiv.org/abs/2312.08007)|**[link](https://github.com/rubics-xuan/mres)**|
|**2023-12-01**|**Towards Generalizable Referring Image Segmentation via Target Prompt and Visual Coherence**|Yajie Liu et.al.|[2312.00452](http://arxiv.org/abs/2312.00452)|null|
|**2023-11-30**|**InstructSeq: Unifying Vision Tasks with Instruction-conditioned Multi-modal Sequence Generation**|Rongyao Fang et.al.|[2311.18835](http://arxiv.org/abs/2311.18835)|null|
|**2023-11-29**|**Synchronizing Vision and Language: Bidirectional Token-Masking AutoEncoder for Referring Image Segmentation**|Minhyeok Lee et.al.|[2311.17952](http://arxiv.org/abs/2311.17952)|null|
|**2024-05-21**|**RISAM: Referring Image Segmentation via Mutual-Aware Attention Features**|Mengxi Zhang et.al.|[2311.15727](http://arxiv.org/abs/2311.15727)|null|
|**2023-11-22**|**Visual In-Context Prompting**|Feng Li et.al.|[2311.13601](http://arxiv.org/abs/2311.13601)|**[link](https://github.com/ux-decoder/dinov)**|
|**2024-04-26**|**Enhancing Visual Grounding and Generalization: A Multi-Task Cycle Training Approach for Vision-Language Models**|Xiaoyu Yang et.al.|[2311.12327](http://arxiv.org/abs/2311.12327)|null|
|**2023-12-18**|**NExT-Chat: An LMM for Chat, Detection and Segmentation**|Ao Zhang et.al.|[2311.04498](http://arxiv.org/abs/2311.04498)|**[link](https://github.com/next-chatv/next-chat)**|
|**2024-06-02**|**GLaMM: Pixel Grounding Large Multimodal Model**|Hanoona Rasheed et.al.|[2311.03356](http://arxiv.org/abs/2311.03356)|**[link](https://github.com/mbzuai-oryx/groundingLMM)**|
|**2023-11-27**|**Towards Omni-supervised Referring Expression Segmentation**|Minglang Huang et.al.|[2311.00397](http://arxiv.org/abs/2311.00397)|**[link](https://github.com/nineblu/omni-res)**|
|**2023-10-27**|**Text Augmented Spatial-aware Zero-shot Referring Image Segmentation**|Yucheng Suo et.al.|[2310.18049](http://arxiv.org/abs/2310.18049)|null|
|**2024-08-20**|**Segment, Select, Correct: A Framework for Weakly-Supervised Referring Segmentation**|Francisco Eiras et.al.|[2310.13479](http://arxiv.org/abs/2310.13479)|**[link](https://github.com/fgirbal/segment-select-correct)**|
|**2023-09-29**|**Towards Complex-query Referring Image Segmentation: A Novel Benchmark**|Wei Ji et.al.|[2309.17205](http://arxiv.org/abs/2309.17205)|null|
|**2023-09-17**|**CLIPUNetr: Assisting Human-robot Interface for Uncalibrated Visual Servoing Control with CLIP-driven Referring Expression Segmentation**|Chen Jiang et.al.|[2309.09183](http://arxiv.org/abs/2309.09183)|null|
|**2024-10-01**|**From Text to Mask: Localizing Entities Using the Attention of Text-to-Image Diffusion Models**|Changming Xiao et.al.|[2309.04109](http://arxiv.org/abs/2309.04109)|**[link](https://github.com/Big-Brother-Pikachu/Text2Mask)**|
|**2023-09-02**|**Contrastive Grouping with Transformer for Referring Image Segmentation**|Jiajin Tang et.al.|[2309.01017](http://arxiv.org/abs/2309.01017)|**[link](https://github.com/toneyaya/cgformer)**|
|**2023-09-01**|**Ref-Diff: Zero-shot Referring Image Segmentation with Generative Models**|Minheng Ni et.al.|[2308.16777](http://arxiv.org/abs/2308.16777)|**[link](https://github.com/kodenii/ref-diff)**|
|**2023-08-31**|**3D-STMN: Dependency-Driven Superpoint-Text Matching Network for End-to-End 3D Referring Expression Segmentation**|Changli Wu et.al.|[2308.16632](http://arxiv.org/abs/2308.16632)|**[link](https://github.com/sosppxo/3d-stmn)**|
|**2023-10-24**|**Shatter and Gather: Learning Referring Image Segmentation with Text Supervision**|Dongwon Kim et.al.|[2308.15512](http://arxiv.org/abs/2308.15512)|**[link](https://github.com/kdwonn/SaG)**|
|**2023-08-28**|**Referring Image Segmentation Using Text Supervision**|Fang Liu et.al.|[2308.14575](http://arxiv.org/abs/2308.14575)|**[link](https://github.com/fawnliu/tris)**|
|**2023-08-26**|**Beyond One-to-One: Rethinking the Referring Image Segmentation**|Yutao Hu et.al.|[2308.13853](http://arxiv.org/abs/2308.13853)|**[link](https://github.com/toggle1995/ris-dmmi)**|
|**2024-10-12**|**EAVL: Explicitly Align Vision and Language for Referring Image Segmentation**|Yichen Yan et.al.|[2308.09779](http://arxiv.org/abs/2308.09779)|null|
|**2023-07-21**|**Bridging Vision and Language Encoders: Parameter-Efficient Tuning for Referring Image Segmentation**|Zunnan Xu et.al.|[2307.11545](http://arxiv.org/abs/2307.11545)|**[link](https://github.com/kkakkkka/etris)**|
|**2024-09-03**|**RefSAM: Efficiently Adapting Segmenting Anything Model for Referring Video Object Segmentation**|Yonglin Li et.al.|[2307.00997](http://arxiv.org/abs/2307.00997)|**[link](https://github.com/lancasterli/refsam)**|
|**2023-06-19**|**WiCo: Win-win Cooperation of Bottom-up and Top-down Referring Image Segmentation**|Zesen Cheng et.al.|[2306.10750](http://arxiv.org/abs/2306.10750)|null|
|**2024-03-01**|**RRSIS: Referring Remote Sensing Image Segmentation**|Zhenghang Yuan et.al.|[2306.08625](http://arxiv.org/abs/2306.08625)|null|
|**2024-04-07**|**Extending CLIP's Image-Text Alignment to Referring Image Segmentation**|Seoyeon Kim et.al.|[2306.08498](http://arxiv.org/abs/2306.08498)|null|
|**2023-06-01**|**GRES: Generalized Referring Expression Segmentation**|Chang Liu et.al.|[2306.00968](http://arxiv.org/abs/2306.00968)|**[link](https://github.com/henghuiding/ReLA)**|
|**2024-08-12**|**Contextual Object Detection with Multimodal Large Language Models**|Yuhang Zang et.al.|[2305.18279](http://arxiv.org/abs/2305.18279)|**[link](https://github.com/yuhangzang/contextdet)**|
|**2023-05-24**|**Multi-Modal Mutual Attention and Iterative Interaction for Referring Image Segmentation**|Chang Liu et.al.|[2305.15302](http://arxiv.org/abs/2305.15302)|null|
|**2023-05-24**|**MMNet: Multi-Mask Network for Referring Image Segmentation**|Yichen Yan et.al.|[2305.14969](http://arxiv.org/abs/2305.14969)|null|
|**2023-05-21**|**Advancing Referring Expression Segmentation Beyond Single Image**|Yixuan Wu et.al.|[2305.12452](http://arxiv.org/abs/2305.12452)|null|
|**2024-02-14**|**CM-MaskSD: Cross-Modality Masked Self-Distillation for Referring Image Segmentation**|Wenxuan Wang et.al.|[2305.11481](http://arxiv.org/abs/2305.11481)|null|
|**2023-04-12**|**Meta Compositional Referring Expression Segmentation**|Li Xu et.al.|[2304.04415](http://arxiv.org/abs/2304.04415)|null|
|**2023-04-03**|**Zero-shot Referring Image Segmentation with Global-Local Context Features**|Seonghoon Yu et.al.|[2303.17811](http://arxiv.org/abs/2303.17811)|**[link](https://github.com/seonghoon-yu/zero-shot-ris)**|
|**2023-03-11**|**Semantics-Aware Dynamic Localization and Refinement for Referring Image Segmentation**|Zhao Yang et.al.|[2303.06345](http://arxiv.org/abs/2303.06345)|null|
|**2023-03-03**|**Unleashing Text-to-Image Diffusion Models for Visual Perception**|Wenliang Zhao et.al.|[2303.02153](http://arxiv.org/abs/2303.02153)|**[link](https://github.com/wl-zhao/VPD)**|
|**2023-03-27**|**PolyFormer: Referring Image Segmentation as Sequential Polygon Generation**|Jiang Liu et.al.|[2302.07387](http://arxiv.org/abs/2302.07387)|**[link](https://github.com/amazon-science/polygon-transformer)**|
|**2023-03-22**|**Linguistic Query-Guided Mask Generation for Referring Image Segmentation**|Zhichao Wei et.al.|[2301.06429](http://arxiv.org/abs/2301.06429)|null|
|**2022-12-27**|**Position-Aware Contrastive Alignment for Referring Image Segmentation**|Bo Chen et.al.|[2212.13419](http://arxiv.org/abs/2212.13419)|null|
|**2022-12-17**|**Fully and Weakly Supervised Referring Expression Segmentation with End-to-End Learning**|Hui Li et.al.|[2212.10278](http://arxiv.org/abs/2212.10278)|null|
|**2022-12-04**|**CoupAlign: Coupling Word-Pixel with Sentence-Mask Alignments for Referring Image Segmentation**|Zicheng Zhang et.al.|[2212.01769](http://arxiv.org/abs/2212.01769)|null|
|**2022-11-15**|**A Unified Mutual Supervision Framework for Referring Expression Segmentation and Generation**|Shijia Huang et.al.|[2211.07919](http://arxiv.org/abs/2211.07919)|null|
|**2022-09-21**|**Exploring Modulated Detection Transformer as a Tool for Action Recognition in Videos**|Tomás Crisol et.al.|[2209.10126](http://arxiv.org/abs/2209.10126)|**[link](https://github.com/bhi-research/ava_mdetr)**|
|**2023-07-23**|**Towards Robust Referring Image Segmentation**|Jianzong Wu et.al.|[2209.09554](http://arxiv.org/abs/2209.09554)|**[link](https://github.com/jianzongwu/robust-ref-seg)**|
|**2022-05-12**|**Weakly-supervised segmentation of referring expressions**|Robin Strudel et.al.|[2205.04725](http://arxiv.org/abs/2205.04725)|null|
|**2022-03-31**|**ReSTR: Convolution-free Referring Image Segmentation Using Transformers**|Namyup Kim et.al.|[2203.16768](http://arxiv.org/abs/2203.16768)|null|
|**2021-12-24**|**Grounding Linguistic Commands to Navigable Regions**|Nivedita Rufus et.al.|[2112.13031](http://arxiv.org/abs/2112.13031)|**[link](https://github.com/kanji95/Talk2car-Refseg)**|
|**2022-03-30**|**Image Segmentation Using Text and Image Prompts**|Timo Lüddecke et.al.|[2112.10003](http://arxiv.org/abs/2112.10003)|**[link](https://github.com/timojl/clipseg)**|
|**2022-04-05**|**LAVT: Language-Aware Vision Transformer for Referring Image Segmentation**|Zhao Yang et.al.|[2112.02244](http://arxiv.org/abs/2112.02244)|**[link](https://github.com/yz93/lavt-ris)**|
|**2022-03-14**|**CRIS: CLIP-Driven Referring Image Segmentation**|Zhaoqing Wang et.al.|[2111.15174](http://arxiv.org/abs/2111.15174)|**[link](https://github.com/DerrickWang005/CRIS.pytorch)**|
|**2021-11-25**|**MaIL: A Unified Mask-Image-Language Trimodal Network for Referring Image Segmentation**|Zizhang Li et.al.|[2111.10747](http://arxiv.org/abs/2111.10747)|null|
|**2021-10-09**|**Two-stage Visual Cues Enhancement Network for Referring Image Segmentation**|Yang Jiao et.al.|[2110.04435](http://arxiv.org/abs/2110.04435)|**[link](https://github.com/sxjyjay/tv-net)**|
|**2021-06-16**|**CMF: Cascaded Multi-model Fusion for Referring Image Segmentation**|Jianhua Yang et.al.|[2106.08617](http://arxiv.org/abs/2106.08617)|**[link](https://github.com/jianhua2022/CMF-Refseg)**|
|**2021-05-15**|**Cross-Modal Progressive Comprehension for Referring Segmentation**|Si Liu et.al.|[2105.07175](http://arxiv.org/abs/2105.07175)|**[link](https://github.com/spyflying/CMPC-Refseg)**|
|**2021-05-05**|**Encoder Fusion Network with Co-Attention Embedding for Referring Image Segmentation**|Guang Feng et.al.|[2105.01839](http://arxiv.org/abs/2105.01839)|null|
|**2022-08-14**|**Comprehensive Multi-Modal Interactions for Referring Image Segmentation**|Kanishk Jain et.al.|[2104.10412](http://arxiv.org/abs/2104.10412)|**[link](https://github.com/kanji95/SHNET)**|
|**2021-03-30**|**Locate then Segment: A Strong Pipeline for Referring Image Segmentation**|Ya Jing et.al.|[2103.16284](http://arxiv.org/abs/2103.16284)|null|
|**2021-04-14**|**OCID-Ref: A 3D Robotic Dataset with Embodied Language for Clutter Scene Grounding**|Ke-Jyun Wang et.al.|[2103.07679](http://arxiv.org/abs/2103.07679)|**[link](https://github.com/lluma/OCID-Ref)**|
|**2020-10-05**|**Linguistic Structure Guided Context Modeling for Referring Image Segmentation**|Tianrui Hui et.al.|[2010.00515](http://arxiv.org/abs/2010.00515)|**[link](https://github.com/spyflying/LSCM-Refseg)**|
|**2020-10-01**|**Referring Image Segmentation via Cross-Modal Progressive Comprehension**|Shaofei Huang et.al.|[2010.00514](http://arxiv.org/abs/2010.00514)|**[link](https://github.com/spyflying/CMPC-Refseg)**|
|**2022-06-23**|**Modulating Bottom-Up and Top-Down Visual Processing via Language-Conditional Filters**|İlker Kesen et.al.|[2003.12739](http://arxiv.org/abs/2003.12739)|**[link](https://github.com/ilkerkesen/bvpr)**|
|**2020-01-30**|**Dual Convolutional LSTM Network for Referring Image Segmentation**|Linwei Ye et.al.|[2001.11561](http://arxiv.org/abs/2001.11561)|null|
|**2019-04-09**|**Cross-Modal Self-Attention Network for Referring Image Segmentation**|Linwei Ye et.al.|[1904.04745](http://arxiv.org/abs/1904.04745)|null|
|**2019-04-06**|**CLEVR-Ref+: Diagnosing Visual Reasoning with Referring Expressions**|Runtao Liu et.al.|[1901.00850](http://arxiv.org/abs/1901.00850)|null|
|**2017-08-04**|**Recurrent Multimodal Interaction for Referring Image Segmentation**|Chenxi Liu et.al.|[1703.07939](http://arxiv.org/abs/1703.07939)|**[link](https://github.com/chenxi116/TF-phrasecut-public)**|

<p align=right>(<a href=#updated-on-20250806>back to top</a>)</p>

## RVOS

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-07-05**|**VideoMolmo: Spatio-Temporal Grounding Meets Pointing**|Ghazi Shazan Ahmad et.al.|[2506.05336](http://arxiv.org/abs/2506.05336)|**[link](https://github.com/mbzuai-oryx/videomolmo)**|
|**2025-06-04**|**InterRVOS: Interaction-aware Referring Video Object Segmentation**|Woojeong Jin et.al.|[2506.02356](http://arxiv.org/abs/2506.02356)|null|
|**2025-05-19**|**Long-RVOS: A Comprehensive Benchmark for Long-term Referring Video Object Segmentation**|Tianming Liang et.al.|[2505.12702](http://arxiv.org/abs/2505.12702)|null|
|**2025-04-18**|**Few-Shot Referring Video Single- and Multi-Object Segmentation via Cross-Modal Affinity with Instance Sequence Matching**|Heng Liu et.al.|[2504.13710](http://arxiv.org/abs/2504.13710)|**[link](https://github.com/hengliusky/few_shot_rvos)**|
|**2025-04-10**|**GLUS: Global-Local Reasoning Unified into A Single Large Language Model for Video Segmentation**|Lang Lin et.al.|[2504.07962](http://arxiv.org/abs/2504.07962)|null|
|**2025-04-07**|**The 1st Solution for 4th PVUW MeViS Challenge: Unleashing the Potential of Large Multimodal Models for Referring Video Segmentation**|Hao Fang et.al.|[2504.05178](http://arxiv.org/abs/2504.05178)|null|
|**2025-04-01**|**4th PVUW MeViS 3rd Place Report: Sa2VA**|Haobo Yuan et.al.|[2504.00476](http://arxiv.org/abs/2504.00476)|**[link](https://github.com/magic-research/Sa2VA)**|
|**2025-05-29**|**ReferDINO-Plus: 2nd Solution for 4th PVUW MeViS Challenge at CVPR 2025**|Tianming Liang et.al.|[2503.23509](http://arxiv.org/abs/2503.23509)|**[link](https://github.com/isee-laboratory/referdino-plus)**|
|**2025-03-05**|**Find First, Track Next: Decoupling Identification and Propagation in Referring Video Object Segmentation**|Suhwan Cho et.al.|[2503.03492](http://arxiv.org/abs/2503.03492)|**[link](https://github.com/suhwan-cho/FindTrack)**|
|**2025-04-12**|**Text-Promptable Propagation for Referring Medical Image Sequence Segmentation**|Runtian Yuan et.al.|[2502.11093](http://arxiv.org/abs/2502.11093)|null|
|**2025-06-30**|**ReferDINO: Referring Video Object Segmentation with Visual Grounding Foundations**|Tianming Liang et.al.|[2501.14607](http://arxiv.org/abs/2501.14607)|null|
|**2025-07-12**|**MPG-SAM 2: Adapting SAM 2 with Mask Priors and Global Context for Referring Video Object Segmentation**|Fu Rong et.al.|[2501.13667](http://arxiv.org/abs/2501.13667)|null|
|**2025-01-15**|**Multi-Context Temporal Consistent Modeling for Referring Video Object Segmentation**|Sun-Hyuk Choi et.al.|[2501.04939](http://arxiv.org/abs/2501.04939)|**[link](https://github.com/choi58/mtcm)**|
|**2025-02-13**|**Sa2VA: Marrying SAM2 with LLaVA for Dense Grounded Understanding of Images and Videos**|Haobo Yuan et.al.|[2501.04001](http://arxiv.org/abs/2501.04001)|**[link](https://github.com/magic-research/Sa2VA)**|
|**2025-03-26**|**Referring Video Object Segmentation via Language-aligned Track Selection**|Seongchan Kim et.al.|[2412.01136](http://arxiv.org/abs/2412.01136)|**[link](https://github.com/cvlab-kaist/SOLA)**|
|**2025-03-25**|**SAMWISE: Infusing Wisdom in SAM2 for Text-Driven Video Segmentation**|Claudia Cuttano et.al.|[2411.17646](http://arxiv.org/abs/2411.17646)|**[link](https://github.com/claudiacuttano/samwise)**|
|**2024-09-09**|**LSVOS Challenge Report: Large-scale Complex and Long Video Object Segmentation**|Henghui Ding et.al.|[2409.05847](http://arxiv.org/abs/2409.05847)|null|
|**2024-08-22**|**The 2nd Solution for LSVOS Challenge RVOS Track: Spatial-temporal Refinement for Consistent Semantic Segmentation**|Tuyen Tran et.al.|[2408.12447](http://arxiv.org/abs/2408.12447)|null|
|**2024-08-20**|**The Instance-centric Transformer for the RVOS Track of LSVOS Challenge: 3rd Place Solution**|Bin Cao et.al.|[2408.10541](http://arxiv.org/abs/2408.10541)|null|
|**2024-08-24**|**UNINEXT-Cutie: The 1st Solution for LSVOS Challenge RVOS Track**|Hao Fang et.al.|[2408.10129](http://arxiv.org/abs/2408.10129)|null|
|**2024-07-10**|**ActionVOS: Actions as Prompts for Video Object Segmentation**|Liangyang Ouyang et.al.|[2407.07402](http://arxiv.org/abs/2407.07402)|**[link](https://github.com/ut-vision/actionvos)**|
|**2024-06-20**|**2nd Place Solution for MeViS Track in CVPR 2024 PVUW Workshop: Motion Expression guided Video Segmentation**|Bin Cao et.al.|[2406.13939](http://arxiv.org/abs/2406.13939)|null|
|**2024-06-23**|**GroPrompt: Efficient Grounded Prompting and Adaptation for Referring Video Object Segmentation**|Ci-Siang Lin et.al.|[2406.12834](http://arxiv.org/abs/2406.12834)|null|
|**2024-06-11**|**1st Place Solution for MeViS Track in CVPR 2024 PVUW Workshop: Motion Expression guided Video Segmentation**|Mingqi Gao et.al.|[2406.07043](http://arxiv.org/abs/2406.07043)|**[link](https://github.com/tapall-ai/mevis_track_solution_2024)**|
|**2024-06-07**|**3rd Place Solution for MeViS Track in CVPR 2024 PVUW workshop: Motion Expression guided Video Segmentation**|Feiyu Pan et.al.|[2406.04842](http://arxiv.org/abs/2406.04842)|null|
|**2024-09-22**|**Harnessing Vision-Language Pretrained Models with Temporal-Aware Adaptation for Referring Video Object Segmentation**|Zikun Zhou et.al.|[2405.10610](http://arxiv.org/abs/2405.10610)|null|
|**2024-10-11**|**Temporally Consistent Referring Video Object Segmentation with Hybrid Memory**|Bo Miao et.al.|[2403.19407](http://arxiv.org/abs/2403.19407)|**[link](https://github.com/bo-miao/HTR)**|
|**2024-07-06**|**Exploring Pre-trained Text-to-Video Diffusion Models for Referring Video Object Segmentation**|Zixin Zhu et.al.|[2403.12042](http://arxiv.org/abs/2403.12042)|**[link](https://github.com/buxiangzhiren/vd-it)**|
|**2024-01-01**|**1st Place Solution for 5th LSVOS Challenge: Referring Video Object Segmentation**|Zhuoyan Luo et.al.|[2401.00663](http://arxiv.org/abs/2401.00663)|**[link](https://github.com/robertluo1/iccv2023_rvos_challenge)**|
|**2023-12-29**|**Tracking with Human-Intent Reasoning**|Jiawen Zhu et.al.|[2312.17448](http://arxiv.org/abs/2312.17448)|**[link](https://github.com/jiawen-zhu/trackgpt)**|
|**2023-12-25**|**UniRef++: Segment Every Reference Object in Spatial and Temporal Spaces**|Jiannan Wu et.al.|[2312.15715](http://arxiv.org/abs/2312.15715)|**[link](https://github.com/foundationvision/uniref)**|
|**2023-09-21**|**Fully Transformer-Equipped Architecture for End-to-End Referring Video Object Segmentation**|Ping Li et.al.|[2309.11933](http://arxiv.org/abs/2309.11933)|null|
|**2023-09-07**|**Temporal Collection and Distribution for Referring Video Object Segmentation**|Jiajin Tang et.al.|[2309.03473](http://arxiv.org/abs/2309.03473)|null|
|**2023-09-05**|**Learning Cross-Modal Affinity for Referring Video Object Segmentation Targeting Limited Samples**|Guanghui Li et.al.|[2309.02041](http://arxiv.org/abs/2309.02041)|**[link](https://github.com/hengliusky/few_shot_rvos)**|
|**2023-08-16**|**MeViS: A Large-scale Benchmark for Video Segmentation with Motion Expressions**|Henghui Ding et.al.|[2308.08544](http://arxiv.org/abs/2308.08544)|**[link](https://github.com/henghuiding/MeViS)**|
|**2025-01-17**|**Expression Prompt Collaboration Transformer for Universal Referring Video Object Segmentation**|Jiajun Chen et.al.|[2308.04162](http://arxiv.org/abs/2308.04162)|null|
|**2023-12-15**|**Learning Referring Video Object Segmentation from Weak Annotation**|Wangbo Zhao et.al.|[2308.02162](http://arxiv.org/abs/2308.02162)|null|
|**2023-07-25**|**Spectrum-guided Multi-granularity Referring Video Object Segmentation**|Bo Miao et.al.|[2307.13537](http://arxiv.org/abs/2307.13537)|**[link](https://github.com/bo-miao/sgmg)**|
|**2023-07-18**|**OnlineRefer: A Simple Online Baseline for Referring Video Object Segmentation**|Dongming Wu et.al.|[2307.09356](http://arxiv.org/abs/2307.09356)|**[link](https://github.com/wudongming97/onlinerefer)**|
|**2024-09-03**|**RefSAM: Efficiently Adapting Segmenting Anything Model for Referring Video Object Segmentation**|Yonglin Li et.al.|[2307.00997](http://arxiv.org/abs/2307.00997)|**[link](https://github.com/lancasterli/refsam)**|
|**2023-09-17**|**Bidirectional Correlation-Driven Inter-Frame Interaction Transformer for Referring Video Object Segmentation**|Meng Lan et.al.|[2307.00536](http://arxiv.org/abs/2307.00536)|null|
|**2024-04-02**|**LoSh: Long-Short Text Joint Prediction Network for Referring Video Object Segmentation**|Linfeng Yuan et.al.|[2306.08736](http://arxiv.org/abs/2306.08736)|**[link](https://github.com/linfengyuan1997/losh)**|
|**2023-05-26**|**SOC: Semantic-Assisted Object Cluster for Referring Video Object Segmentation**|Zhuoyan Luo et.al.|[2305.17011](http://arxiv.org/abs/2305.17011)|**[link](https://github.com/RobertLuo1/NeurIPS2023_SOC)**|
|**2023-12-12**|**Referred by Multi-Modality: A Unified Temporal Transformer for Video Object Segmentation**|Shilin Yan et.al.|[2305.16318](http://arxiv.org/abs/2305.16318)|**[link](https://github.com/opengvlab/mutr)**|
|**2022-12-27**|**1st Place Solution for YouTubeVOS Challenge 2022: Referring Video Object Segmentation**|Zhiwei Hu et.al.|[2212.14679](http://arxiv.org/abs/2212.14679)|**[link](https://github.com/zhiweihhh/cvpr2022-rvos-challenge)**|
|**2022-07-26**|**Multi-Attention Network for Compressed Video Referring Object Segmentation**|Weidong Chen et.al.|[2207.12622](http://arxiv.org/abs/2207.12622)|**[link](https://github.com/dexianghong/manet)**|
|**2023-08-18**|**Towards Robust Referring Video Object Segmentation with Cyclic Relational Consensus**|Xiang Li et.al.|[2207.01203](http://arxiv.org/abs/2207.01203)|**[link](https://github.com/lxa9867/R2VOS)**|
|**2022-06-24**|**The Second Place Solution for The 4th Large-scale Video Object Segmentation Challenge--Track 3: Referring Video Object Segmentation**|Leilei Cao et.al.|[2206.12035](http://arxiv.org/abs/2206.12035)|null|
|**2022-06-08**|**Language-Bridged Spatial-Temporal Interaction for Referring Video Object Segmentation**|Zihan Ding et.al.|[2206.03789](http://arxiv.org/abs/2206.03789)|**[link](https://github.com/dzh19990407/lbdt)**|
|**2024-01-19**|**Local-Global Context Aware Transformer for Language-Guided Video Segmentation**|Chen Liang et.al.|[2203.09773](http://arxiv.org/abs/2203.09773)|**[link](https://github.com/leonnnop/locater)**|
|**2022-03-13**|**Language as Queries for Referring Video Object Segmentation**|Jiannan Wu et.al.|[2201.00487](http://arxiv.org/abs/2201.00487)|**[link](https://github.com/wjn922/referformer)**|
|**2022-04-03**|**End-to-End Referring Video Object Segmentation with Multimodal Transformers**|Adam Botach et.al.|[2111.14821](http://arxiv.org/abs/2111.14821)|**[link](https://github.com/mttr2021/MTTR)**|
|**2024-01-19**|**Rethinking Cross-modal Interaction from a Top-down Perspective for Referring Video Object Segmentation**|Chen Liang et.al.|[2106.01061](http://arxiv.org/abs/2106.01061)|null|

<p align=right>(<a href=#updated-on-20250806>back to top</a>)</p>

## RVOT

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2024-03-29**|**Elysium: Exploring Object-level Perception in Videos via MLLM**|Han Wang et.al.|[2403.16558](http://arxiv.org/abs/2403.16558)|**[link](https://github.com/hon-wong/elysium)**|

<p align=right>(<a href=#updated-on-20250806>back to top</a>)</p>

## AVS

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-06-30**|**Revisiting Audio-Visual Segmentation with Vision-Centric Transformer**|Shaofei Huang et.al.|[2506.23623](http://arxiv.org/abs/2506.23623)|null|
|**2025-06-29**|**Mettle: Meta-Token Learning for Memory-Efficient Audio-Visual Adaptation**|Jinxing Zhou et.al.|[2506.23271](http://arxiv.org/abs/2506.23271)|null|
|**2025-06-13**|**TAViS: Text-bridged Audio-Visual Segmentation with Foundation Models**|Ziyang Luo et.al.|[2506.11436](http://arxiv.org/abs/2506.11436)|null|
|**2025-06-02**|**SAM2-LOVE: Segment Anything Model 2 in Language-aided Audio-Visual Scenes**|Yuji Wang et.al.|[2506.01558](http://arxiv.org/abs/2506.01558)|null|
|**2025-05-26**|**Omni-R1: Reinforcement Learning for Omnimodal Reasoning via Two-System Collaboration**|Hao Zhong et.al.|[2505.20256](http://arxiv.org/abs/2505.20256)|**[link](https://github.com/aim-uofa/omni-r1)**|
|**2025-04-30**|**OpenAVS: Training-Free Open-Vocabulary Audio Visual Segmentation with Foundational Models**|Shengkai Chen et.al.|[2505.01448](http://arxiv.org/abs/2505.01448)|null|
|**2025-03-17**|**Robust Audio-Visual Segmentation via Audio-Guided Visual Convergent Alignment**|Chen Liu et.al.|[2503.12847](http://arxiv.org/abs/2503.12847)|null|
|**2025-03-17**|**Dynamic Derivation and Elimination: Audio Visual Segmentation with Enhanced Audio Semantics**|Chen Liu et.al.|[2503.12840](http://arxiv.org/abs/2503.12840)|**[link](https://github.com/YenanLiu/DDESeg)**|
|**2025-05-29**|**Audio Visual Segmentation Through Text Embeddings**|Kyungbok Lee et.al.|[2502.16359](http://arxiv.org/abs/2502.16359)|**[link](https://github.com/bok-bok/av2t-sam)**|
|**2025-02-20**|**Do Audio-Visual Segmentation Models Truly Segment Sounding Objects?**|Jia Li et.al.|[2502.00358](http://arxiv.org/abs/2502.00358)|null|
|**2025-01-14**|**AVS-Mamba: Exploring Temporal and Multi-modal Mamba for Audio-Visual Segmentation**|Sitong Gong et.al.|[2501.07810](http://arxiv.org/abs/2501.07810)|**[link](https://github.com/sitonggong/avs-mamba)**|
|**2024-12-17**|**Multimodal Class-aware Semantic Enhancement Network for Audio-Visual Video Parsing**|Pengcheng Zhao et.al.|[2412.11248](http://arxiv.org/abs/2412.11248)|null|
|**2024-12-11**|**Collaborative Hybrid Propagator for Temporal Misalignment in Audio-Visual Segmentation**|Kexin Li et.al.|[2412.08161](http://arxiv.org/abs/2412.08161)|null|
|**2024-11-04**|**3D Audio-Visual Segmentation**|Artem Sokolov et.al.|[2411.02236](http://arxiv.org/abs/2411.02236)|null|
|**2024-08-03**|**AVESFormer: Efficient Transformer Design for Real-Time Audio-Visual Segmentation**|Zili Wang et.al.|[2408.01708](http://arxiv.org/abs/2408.01708)|**[link](https://github.com/markxcloud/avesformer)**|
|**2024-07-23**|**Unveiling and Mitigating Bias in Audio Visual Segmentation**|Peiwen Sun et.al.|[2407.16638](http://arxiv.org/abs/2407.16638)|null|
|**2024-09-12**|**Stepping Stones: A Progressive Training Strategy for Audio-Visual Semantic Segmentation**|Juncheng Ma et.al.|[2407.11820](http://arxiv.org/abs/2407.11820)|**[link](https://github.com/GeWu-Lab/Stepping-Stones)**|
|**2024-07-15**|**Ref-AVS: Refer and Segment Objects in Audio-Visual Scenes**|Yaoting Wang et.al.|[2407.10957](http://arxiv.org/abs/2407.10957)|null|
|**2024-07-15**|**Can Textual Semantics Mitigate Sounding Object Segmentation Preference?**|Yaoting Wang et.al.|[2407.10947](http://arxiv.org/abs/2407.10947)|**[link](https://github.com/gewu-lab/sounding-object-segmentation-preference)**|
|**2024-07-11**|**Label-anticipated Event Disentanglement for Audio-Visual Video Parsing**|Jinxing Zhou et.al.|[2407.08126](http://arxiv.org/abs/2407.08126)|null|
|**2024-09-29**|**CPM: Class-conditional Prompting Machine for Audio-visual Segmentation**|Yuanhong Chen et.al.|[2407.05358](http://arxiv.org/abs/2407.05358)|null|
|**2024-07-03**|**SAVE: Segment Audio-Visual Easy way using Segment Anything Model**|Khanh-Binh Nguyen et.al.|[2407.02004](http://arxiv.org/abs/2407.02004)|null|
|**2024-06-10**|**Extending Segment Anything Model into Auditory and Temporal Dimensions for Audio-Visual Segmentation**|Juhyeong Seon et.al.|[2406.06163](http://arxiv.org/abs/2406.06163)|**[link](https://github.com/Sunjuhyeong/SAM_STBAVA)**|
|**2025-02-10**|**Progressive Confident Masking Attention Network for Audio-Visual Segmentation**|Yuxuan Wang et.al.|[2406.02345](http://arxiv.org/abs/2406.02345)|**[link](https://github.com/prettyplate/pcmanet)**|
|**2024-03-21**|**Unsupervised Audio-Visual Segmentation with Modality Alignment**|Swapnil Bhosale et.al.|[2403.14203](http://arxiv.org/abs/2403.14203)|null|
|**2024-03-17**|**Audio-Visual Segmentation via Unlabeled Frame Exploitation**|Jinxiang Liu et.al.|[2403.11074](http://arxiv.org/abs/2403.11074)|null|
|**2024-02-06**|**Bootstrapping Audio-Visual Segmentation by Strengthening Audio Cues**|Tianxiang Chen et.al.|[2402.02327](http://arxiv.org/abs/2402.02327)|null|
|**2024-04-07**|**Cooperation Does Matter: Exploring Multi-Order Bilateral Relations for Audio-Visual Segmentation**|Qi Yang et.al.|[2312.06462](http://arxiv.org/abs/2312.06462)|**[link](https://github.com/yannqi/COMBO-AVS)**|
|**2023-12-02**|**Unveiling the Power of Audio-Visual Early Fusion Transformers with Dense Interactions through Masked Modeling**|Shentong Mo et.al.|[2312.01017](http://arxiv.org/abs/2312.01017)|**[link](https://github.com/stonemo/deepavfusion)**|
|**2023-11-25**|**Weakly-Supervised Audio-Visual Segmentation**|Shentong Mo et.al.|[2311.15080](http://arxiv.org/abs/2311.15080)|null|
|**2023-10-12**|**Multimodal Variational Auto-encoder based Audio-Visual Segmentation**|Yuxin Mao et.al.|[2310.08303](http://arxiv.org/abs/2310.08303)|**[link](https://github.com/opennlplab/mmvae-avs)**|
|**2024-07-17**|**Cross-modal Cognitive Consensus guided Audio-Visual Segmentation**|Zhaofeng Shi et.al.|[2310.06259](http://arxiv.org/abs/2310.06259)|**[link](https://github.com/zhaofengshi/avs-c3n)**|
|**2023-09-18**|**Discovering Sounding Objects by Audio Queries for Audio Visual Segmentation**|Shaofei Huang et.al.|[2309.09501](http://arxiv.org/abs/2309.09501)|null|
|**2023-09-13**|**Leveraging Foundation models for Unsupervised Audio-Visual Segmentation**|Swapnil Bhosale et.al.|[2309.06728](http://arxiv.org/abs/2309.06728)|null|
|**2023-08-20**|**BAVS: Bootstrapping Audio-Visual Segmentation by Integrating Foundation Knowledge**|Chen Liu et.al.|[2308.10175](http://arxiv.org/abs/2308.10175)|null|
|**2023-12-19**|**Improving Audio-Visual Segmentation with Bidirectional Generation**|Dawei Hao et.al.|[2308.08288](http://arxiv.org/abs/2308.08288)|**[link](https://github.com/opennlplab/avs-bidirectional)**|
|**2023-08-10**|**Progressive Spatio-temporal Perception for Audio-Visual Question Answering**|Guangyao Li et.al.|[2308.05421](http://arxiv.org/abs/2308.05421)|**[link](https://github.com/gewu-lab/pstp-net)**|
|**2023-08-01**|**Audio-Visual Segmentation by Exploring Cross-Modal Mutual Semantics**|Chen Liu et.al.|[2307.16620](http://arxiv.org/abs/2307.16620)|null|
|**2025-07-01**|**Contrastive Conditional Latent Diffusion for Audio-visual Segmentation**|Yuxin Mao et.al.|[2307.16579](http://arxiv.org/abs/2307.16579)|null|
|**2023-07-25**|**Audio-aware Query-enhanced Transformer for Audio-Visual Segmentation**|Jinxiang Liu et.al.|[2307.13236](http://arxiv.org/abs/2307.13236)|null|
|**2023-12-18**|**AVSegFormer: Audio-Visual Segmentation with Transformer**|Shengyi Gao et.al.|[2307.01146](http://arxiv.org/abs/2307.01146)|**[link](https://github.com/vvvb-github/avsegformer)**|
|**2023-10-07**|**Annotation-free Audio-Visual Segmentation**|Jinxiang Liu et.al.|[2305.11019](http://arxiv.org/abs/2305.11019)|null|
|**2023-12-26**|**Transavs: End-To-End Audio-Visual Segmentation With Transformer**|Yuhang Ling et.al.|[2305.07223](http://arxiv.org/abs/2305.07223)|null|
|**2023-05-03**|**AV-SAM: Segment Anything Model Meets Audio-Visual Localization and Segmentation**|Shentong Mo et.al.|[2305.01836](http://arxiv.org/abs/2305.01836)|null|
|**2024-09-17**|**MED-VT++: Unifying Multimodal Learning with a Multiscale Encoder-Decoder Video Transformer**|Rezaul Karim et.al.|[2304.05930](http://arxiv.org/abs/2304.05930)|null|
|**2024-08-14**|**Unraveling Instance Associations: A Closer Look for Audio-Visual Segmentation**|Yuanhong Chen et.al.|[2304.02970](http://arxiv.org/abs/2304.02970)|**[link](https://github.com/cyh-0/CAVP)**|
|**2023-01-30**|**Audio-Visual Segmentation with Semantics**|Jinxing Zhou et.al.|[2301.13190](http://arxiv.org/abs/2301.13190)|**[link](https://github.com/opennlplab/avsbench)**|
|**2023-02-17**|**Audio-Visual Segmentation**|Jinxing Zhou et.al.|[2207.05042](http://arxiv.org/abs/2207.05042)|**[link](https://github.com/opennlplab/avsbench)**|
|**2021-04-05**|**Positive Sample Propagation along the Audio-Visual Event Line**|Jinxing Zhou et.al.|[2104.00239](http://arxiv.org/abs/2104.00239)|**[link](https://github.com/jasongief/PSP_CVPR_2021)**|

<p align=right>(<a href=#updated-on-20250806>back to top</a>)</p>

## 3D-RES

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-04-17**|**3DResT: A Strong Baseline for Semi-Supervised 3D Referring Expression Segmentation**|Wenxin Chen et.al.|[2504.12599](http://arxiv.org/abs/2504.12599)|null|
|**2025-01-09**|**IPDN: Image-enhanced Prompt Decoding Network for 3D Referring Expression Segmentation**|Qi Chen et.al.|[2501.04995](http://arxiv.org/abs/2501.04995)|**[link](https://github.com/80chen86/ipdn)**|
|**2024-12-22**|**RG-SAN: Rule-Guided Spatial Awareness Network for End-to-End 3D Referring Expression Segmentation**|Changli Wu et.al.|[2412.02402](http://arxiv.org/abs/2412.02402)|**[link](https://github.com/sosppxo/rg-san)**|
|**2024-07-31**|**3D-GRES: Generalized 3D Referring Expression Segmentation**|Changli Wu et.al.|[2407.20664](http://arxiv.org/abs/2407.20664)|**[link](https://github.com/sosppxo/MDIN)**|
|**2023-08-31**|**3D-STMN: Dependency-Driven Superpoint-Text Matching Network for End-to-End 3D Referring Expression Segmentation**|Changli Wu et.al.|[2308.16632](http://arxiv.org/abs/2308.16632)|**[link](https://github.com/sosppxo/3d-stmn)**|

<p align=right>(<a href=#updated-on-20250806>back to top</a>)</p>

## Poster Generation

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-07-06**|**DreamPoster: A Unified Framework for Image-Conditioned Generative Poster Design**|Xiwei Hu et.al.|[2507.04218](http://arxiv.org/abs/2507.04218)|null|
|**2025-06-12**|**PosterCraft: Rethinking High-Quality Aesthetic Poster Generation in a Unified Framework**|SiXiang Chen et.al.|[2506.10741](http://arxiv.org/abs/2506.10741)|null|
|**2025-06-03**|**Generalized Category Discovery via Reciprocal Learning and Class-Wise Distribution Regularization**|Duo Liu et.al.|[2506.02334](http://arxiv.org/abs/2506.02334)|null|
|**2025-05-27**|**Paper2Poster: Towards Multimodal Poster Automation from Scientific Papers**|Wei Pang et.al.|[2505.21497](http://arxiv.org/abs/2505.21497)|**[link](https://github.com/paper2poster/paper2poster)**|
|**2025-05-21**|**P2P: Automated Paper-to-Poster Generation and Fine-Grained Benchmark**|Tao Sun et.al.|[2505.17104](http://arxiv.org/abs/2505.17104)|**[link](https://github.com/multimodal-art-projection/P2P)**|
|**2025-04-09**|**PosterMaker: Towards High-Quality Product Poster Generation with Accurate Text Rendering**|Yifan Gao et.al.|[2504.06632](http://arxiv.org/abs/2504.06632)|null|
|**2025-03-19**|**POSTA: A Go-to Framework for Customized Artistic Poster Generation**|Haoyu Chen et.al.|[2503.14908](http://arxiv.org/abs/2503.14908)|null|
|**2024-10-22**|**MPDS: A Movie Posters Dataset for Image Generation with Diffusion Model**|Meng Xu et.al.|[2410.16840](http://arxiv.org/abs/2410.16840)|null|
|**2025-02-02**|**Personalized Image Generation with Large Multimodal Models**|Yiyan Xu et.al.|[2410.14170](http://arxiv.org/abs/2410.14170)|**[link](https://github.com/yiyanxu/pigeon)**|
|**2024-07-29**|**SciPostLayout: A Dataset for Layout Analysis and Layout Generation of Scientific Posters**|Shohei Tanaka et.al.|[2407.19787](http://arxiv.org/abs/2407.19787)|null|
|**2025-02-12**|**GlyphDraw2: Automatic Generation of Complex Glyph Posters with Diffusion Models and Large Language Models**|Jian Ma et.al.|[2407.02252](http://arxiv.org/abs/2407.02252)|**[link](https://github.com/oppo-mente-lab/glyphdraw2)**|
|**2024-11-26**|**LTOS: Layout-controllable Text-Object Synthesis via Adaptive Cross-attention Fusions**|Xiaoran Zhao et.al.|[2404.13579](http://arxiv.org/abs/2404.13579)|null|
|**2024-02-10**|**Evaluation Metrics for Automated Typographic Poster Generation**|Sérgio M. Rebelo et.al.|[2402.06945](http://arxiv.org/abs/2402.06945)|**[link](https://github.com/sergiomrebelo/evo-poster)**|
|**2024-09-03**|**Planning and Rendering: Towards Product Poster Generation with Diffusion Models**|Zhaochen Li et.al.|[2312.08822](http://arxiv.org/abs/2312.08822)|null|
|**2023-11-03**|**OpenLEAF: Open-Domain Interleaved Image-Text Generation and Evaluation**|Jie An et.al.|[2310.07749](http://arxiv.org/abs/2310.07749)|null|
|**2023-08-23**|**AutoPoster: A Highly Automatic and Content-aware Design System for Advertising Poster Generation**|Jinpeng Lin et.al.|[2308.01095](http://arxiv.org/abs/2308.01095)|null|
|**2023-05-26**|**Coarse-to-Fine: a Hierarchical Diffusion Model for Molecule Generation in 3D**|Bo Qiang et.al.|[2305.13266](http://arxiv.org/abs/2305.13266)|**[link](https://github.com/qiangbo1222/hierdiff)**|
|**2023-03-25**|**Unsupervised Domain Adaption with Pixel-level Discriminator for Image-aware Layout Generation**|Chenchen Xu et.al.|[2303.14377](http://arxiv.org/abs/2303.14377)|null|
|**2023-01-06**|**Text2Poster: Laying out Stylized Texts on Retrieved Images**|Chuhao Jin et.al.|[2301.02363](http://arxiv.org/abs/2301.02363)|**[link](https://github.com/chuhaojin/text2poster-icassp-22)**|
|**2021-12-29**|**Overcoming Mode Collapse with Adaptive Multi Adversarial Training**|Karttikeya Mangalam et.al.|[2112.14406](http://arxiv.org/abs/2112.14406)|**[link](https://github.com/gargrohin/amat)**|
|**2021-12-16**|**Neural Content Extraction for Poster Generation of Scientific Papers**|Sheng Xu et.al.|[2112.08550](http://arxiv.org/abs/2112.08550)|null|
|**2021-04-22**|**Behavior-Driven Synthesis of Human Dynamics**|Andreas Blattmann et.al.|[2103.04677](http://arxiv.org/abs/2103.04677)|null|

<p align=right>(<a href=#updated-on-20250806>back to top</a>)</p>

## Graphic Design Generation

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-07-08**|**Rethinking Layered Graphic Design Generation with a Top-Down Approach**|Jingye Chen et.al.|[2507.05601](http://arxiv.org/abs/2507.05601)|null|
|**2025-06-12**|**CreatiPoster: Towards Editable and Controllable Multi-Layer Graphic Design Generation**|Zhao Zhang et.al.|[2506.10890](http://arxiv.org/abs/2506.10890)|**[link](https://github.com/graphic-design-ai/creatiposter)**|
|**2025-05-28**|**CreatiDesign: A Unified Multi-Conditional Diffusion Transformer for Creative Graphic Design**|Hui Zhang et.al.|[2505.19114](http://arxiv.org/abs/2505.19114)|null|
|**2024-10-11**|**Can GPTs Evaluate Graphic Design Based on Design Principles?**|Daichi Haraguchi et.al.|[2410.08885](http://arxiv.org/abs/2410.08885)|null|
|**2024-06-12**|**OpenCOLE: Towards Reproducible Automatic Graphic Design Generation**|Naoto Inoue et.al.|[2406.08232](http://arxiv.org/abs/2406.08232)|**[link](https://github.com/cyberagentailab/opencole)**|
|**2024-03-18**|**COLE: A Hierarchical Generation Framework for Multi-Layered and Editable Graphic Design**|Peidong Jia et.al.|[2311.16974](http://arxiv.org/abs/2311.16974)|null|

<p align=right>(<a href=#updated-on-20250806>back to top</a>)</p>

## Layout Generation

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-07-23**|**EarthCrafter: Scalable 3D Earth Generation via Dual-Sparse Latent Diffusion**|Shang Liu et.al.|[2507.16535](http://arxiv.org/abs/2507.16535)|null|
|**2025-07-17**|**Multi-Agent Synergy-Driven Iterative Visual Narrative Synthesis**|Wang Xi et.al.|[2507.13285](http://arxiv.org/abs/2507.13285)|null|
|**2025-07-14**|**IGD: Instructional Graphic Design with Multimodal Layer Generation**|Yadong Qu et.al.|[2507.09910](http://arxiv.org/abs/2507.09910)|null|
|**2025-07-08**|**ReLayout: Integrating Relation Reasoning for Content-aware Layout Generation with Multi-modal Large Language Models**|Jiaxu Tian et.al.|[2507.05568](http://arxiv.org/abs/2507.05568)|null|
|**2025-06-27**|**CAL-RAG: Retrieval-Augmented Multi-Agent Generation for Content-Aware Layout Design**|Najmeh Forouzandehmehr et.al.|[2506.21934](http://arxiv.org/abs/2506.21934)|null|
|**2025-06-16**|**EmbodiedGen: Towards a Generative 3D World Engine for Embodied Intelligence**|Xinjie Wang et.al.|[2506.10600](http://arxiv.org/abs/2506.10600)|null|
|**2025-06-09**|**LLM-driven Indoor Scene Layout Generation via Scaled Human-aligned Data Synthesis and Multi-Stage Preference Optimization**|Yixuan Yang et.al.|[2506.07570](http://arxiv.org/abs/2506.07570)|null|
|**2025-06-08**|**SceneLCM: End-to-End Layout-Guided Interactive Indoor Scene Generation with Latent Consistency Model**|Yangkai Lin et.al.|[2506.07091](http://arxiv.org/abs/2506.07091)|null|
|**2025-06-06**|**Table-r1: Self-supervised and Reinforcement Learning for Program-based Table Reasoning in Small Language Models**|Rihui Jin et.al.|[2506.06137](http://arxiv.org/abs/2506.06137)|null|
|**2025-06-05**|**Direct Numerical Layout Generation for 3D Indoor Scene Synthesis via Spatial Reasoning**|Xingjian Ran et.al.|[2506.05341](http://arxiv.org/abs/2506.05341)|null|
|**2025-06-03**|**LayoutRAG: Retrieval-Augmented Model for Content-agnostic Conditional Layout Generation**|Yuxuan Wu et.al.|[2506.02697](http://arxiv.org/abs/2506.02697)|null|
|**2025-05-27**|**Scan-and-Print: Patch-level Data Summarization and Augmentation for Content-aware Layout Generation in Poster Design**|HsiaoYuan Hsu et.al.|[2505.20649](http://arxiv.org/abs/2505.20649)|null|
|**2025-05-26**|**Aggregated Structural Representation with Large Language Models for Human-Centric Layout Generation**|Jiongchao Jin et.al.|[2505.19554](http://arxiv.org/abs/2505.19554)|null|
|**2025-07-17**|**TextDiffuser-RL: Efficient and Robust Text Layout Optimization for High-Fidelity Text-to-Image Synthesis**|Kazi Mahathir Rahman et.al.|[2505.19291](http://arxiv.org/abs/2505.19291)|null|
|**2025-05-27**|**PosterO: Structuring Layout Trees to Enable Language Models in Generalized Content-Aware Layout Generation**|HsiaoYuan Hsu et.al.|[2505.07843](http://arxiv.org/abs/2505.07843)|null|
|**2025-05-07**|**Lay-Your-Scene: Natural Scene Layout Generation with Diffusion Transformers**|Divyansh Srivastava et.al.|[2505.04718](http://arxiv.org/abs/2505.04718)|null|
|**2025-05-07**|**BuildingBlock: A Hybrid Approach for Structured Building Generation**|Junming Huang et.al.|[2505.04051](http://arxiv.org/abs/2505.04051)|null|
|**2025-05-02**|**Generating Animated Layouts as Structured Text Representations**|Yeonsang Shin et.al.|[2505.00975](http://arxiv.org/abs/2505.00975)|null|
|**2025-02-05**|**Digital Kitchen Remodeling: Editing and Relighting Intricate Indoor Scenes from a Single Panorama**|Guanzhou Ji et.al.|[2504.16086](http://arxiv.org/abs/2504.16086)|null|
|**2025-04-15**|**LayoutCoT: Unleashing the Deep Reasoning Potential of Large Language Models for Layout Generation**|Hengyu Shi et.al.|[2504.10829](http://arxiv.org/abs/2504.10829)|null|
|**2025-04-14**|**Relation-Rich Visual Document Generator for Visual Information Extraction**|Zi-Han Jiang et.al.|[2504.10659](http://arxiv.org/abs/2504.10659)|**[link](https://github.com/ai-application-and-integration-lab/ridge)**|
|**2025-04-14**|**Decoupled Diffusion Sparks Adaptive Scene Generation**|Yunsong Zhou et.al.|[2504.10485](http://arxiv.org/abs/2504.10485)|null|
|**2025-04-21**|**Hierarchical and Step-Layer-Wise Tuning of Attention Specialty for Multi-Instance Synthesis in Diffusion Transformers**|Chunyang Zhang et.al.|[2504.10148](http://arxiv.org/abs/2504.10148)|null|
|**2025-04-13**|**Computer-Aided Layout Generation for Building Design: A Review**|Jiachen Liu et.al.|[2504.09694](http://arxiv.org/abs/2504.09694)|null|
|**2025-04-07**|**Imperative vs. Declarative Programming Paradigms for Open-Universe Scene Generation**|Maxim Gumin et.al.|[2504.05482](http://arxiv.org/abs/2504.05482)|null|
|**2025-03-27**|**Efficient Multi-Instance Generation with Janus-Pro-Dirven Prompt Parsing**|Fan Qi et.al.|[2503.21069](http://arxiv.org/abs/2503.21069)|null|
|**2025-03-26**|**RelTriple: Learning Plausible Indoor Layouts by Integrating Relationship Triples into the Diffusion Process**|Kaifan Sun et.al.|[2503.20289](http://arxiv.org/abs/2503.20289)|null|
|**2025-03-25**|**BADGR: Bundle Adjustment Diffusion Conditioned by GRadients for Wide-Baseline Floor Plan Reconstruction**|Yuguang Li et.al.|[2503.19340](http://arxiv.org/abs/2503.19340)|null|
|**2025-03-24**|**MetaSpatial: Reinforcing 3D Spatial Reasoning in VLMs for the Metaverse**|Zhenyu Pan et.al.|[2503.18470](http://arxiv.org/abs/2503.18470)|**[link](https://github.com/pzyseere/metaspatial)**|
|**2025-03-21**|**HSM: Hierarchical Scene Motifs for Multi-Scale Indoor Scene Generation**|Hou In Derek Pun et.al.|[2503.16848](http://arxiv.org/abs/2503.16848)|null|
|**2025-03-01**|**AesthetiQ: Enhancing Graphic Layout Design via Aesthetic-Aware Preference Alignment of Multi-modal Large Language Models**|Sohan Patnaik et.al.|[2503.00591](http://arxiv.org/abs/2503.00591)|null|
|**2025-05-22**|**FoREST: Frame of Reference Evaluation in Spatial Reasoning Tasks**|Tanawan Premsri et.al.|[2502.17775](http://arxiv.org/abs/2502.17775)|**[link](https://github.com/HLR/FoREST)**|
|**2025-02-21**|**Textual-to-Visual Iterative Self-Verification for Slide Generation**|Yunqing Xu et.al.|[2502.15412](http://arxiv.org/abs/2502.15412)|null|
|**2025-02-19**|**Smaller But Better: Unifying Layout Generation with Smaller Large Language Models**|Peirong Zhang et.al.|[2502.14005](http://arxiv.org/abs/2502.14005)|**[link](https://github.com/niceringnode/lggpt)**|
|**2025-02-12**|**RouteFlow: Trajectory-Aware Animated Transitions**|Duan Li et.al.|[2502.08076](http://arxiv.org/abs/2502.08076)|**[link](https://github.com/Trajectory-Anim/Trajectory-Aware-Animated-Transitions)**|
|**2025-02-06**|**Illuminating Spaces: Deep Reinforcement Learning and Laser-Wall Partitioning for Architectural Layout Generation**|Reza Kakooee et.al.|[2502.04407](http://arxiv.org/abs/2502.04407)|null|
|**2025-02-12**|**PAID: A Framework of Product-Centric Advertising Image Design**|Hongyu Chen et.al.|[2501.14316](http://arxiv.org/abs/2501.14316)|null|
|**2025-01-16**|**Text Semantics to Flexible Design: A Residential Layout Generation Method Based on Stable Diffusion Model**|Zijin Qiu et.al.|[2501.09279](http://arxiv.org/abs/2501.09279)|null|
|**2025-06-28**|**Compositional Generative Model of Unbounded 4D Cities**|Haozhe Xie et.al.|[2501.08983](http://arxiv.org/abs/2501.08983)|**[link](https://github.com/hzxie/CityDreamer4D)**|
|**2025-01-09**|**Spatial Information Integration in Small Language Models for Document Layout Generation and Classification**|Pablo Melendez et.al.|[2501.05497](http://arxiv.org/abs/2501.05497)|null|
|**2025-01-07**|**SceneBooth: Diffusion-based Framework for Subject-preserved Text-to-Image Generation**|Shang Chai et.al.|[2501.03490](http://arxiv.org/abs/2501.03490)|null|
|**2024-12-20**|**Do we still need canaries in the coal mine? Measuring shadow stack effectiveness in countering stack smashing**|Hugo Depuydt et.al.|[2412.16343](http://arxiv.org/abs/2412.16343)|null|
|**2025-03-12**|**SLayR: Scene Layout Generation with Rectified Flow**|Cameron Braunstein et.al.|[2412.05003](http://arxiv.org/abs/2412.05003)|null|
|**2025-03-11**|**VASCAR: Content-Aware Layout Generation via Visual-Aware Self-Correction**|Jiahao Zhang et.al.|[2412.04237](http://arxiv.org/abs/2412.04237)|null|
|**2025-03-14**|**CreatiLayout: Siamese Multimodal Diffusion Transformer for Creative Layout-to-Image Generation**|Hui Zhang et.al.|[2412.03859](http://arxiv.org/abs/2412.03859)|null|
|**2024-11-27**|**Enhancing Document AI Data Generation Through Graph-Based Synthetic Layouts**|Amit Agarwal et.al.|[2412.03590](http://arxiv.org/abs/2412.03590)|null|
|**2024-11-30**|**DogLayout: Denoising Diffusion GAN for Discrete and Continuous Layout Generation**|Zhaoxing Gan et.al.|[2412.00381](http://arxiv.org/abs/2412.00381)|**[link](https://github.com/deadsmither5/DogLayout)**|
|**2025-01-05**|**SynDCIM: A Performance-Aware Digital Computing-in-Memory Compiler with Multi-Spec-Oriented Subcircuit Synthesis**|Kunming Shao et.al.|[2411.16806](http://arxiv.org/abs/2411.16806)|null|
|**2024-12-02**|**AnySynth: Harnessing the Power of Image Synthetic Data Generation for Generalized Vision-Language Tasks**|You Li et.al.|[2411.16749](http://arxiv.org/abs/2411.16749)|null|
|**2024-11-18**|**GLDesigner: Leveraging Multi-Modal LLMs as Designer for Enhanced Aesthetic Text Glyph Layouts**|Junwen He et.al.|[2411.11435](http://arxiv.org/abs/2411.11435)|null|
|**2024-11-14**|**Scalable Readability Evaluation for Graph Layouts: 2D Geometric Distributed Algorithms**|Sanggeon Yun et.al.|[2411.09809](http://arxiv.org/abs/2411.09809)|null|
|**2024-10-18**|**HiCo: Hierarchical Controllable Diffusion Model for Layout-to-image Generation**|Bo Cheng et.al.|[2410.14324](http://arxiv.org/abs/2410.14324)|**[link](https://github.com/360cvgroup/hico_t2i)**|
|**2025-02-24**|**Decoupling Layout from Glyph in Online Chinese Handwriting Generation**|Min-Si Ren et.al.|[2410.02309](http://arxiv.org/abs/2410.02309)|null|
|**2024-09-25**|**Layout-Corrector: Alleviating Layout Sticking Phenomenon in Discrete Diffusion Model**|Shoma Iwai et.al.|[2409.16689](http://arxiv.org/abs/2409.16689)|null|
|**2024-09-04**|**Spatial Diffusion for Cell Layout Generation**|Chen Li et.al.|[2409.03106](http://arxiv.org/abs/2409.03106)|**[link](https://github.com/superlc1995/diffusion-cell)**|
|**2024-07-26**|**Interactive and Automatic Generation of Primitive Custom Circuit Layout Using LLMs**|Geunyoung You et.al.|[2408.07279](http://arxiv.org/abs/2408.07279)|null|
|**2024-09-06**|**UniPortrait: A Unified Framework for Identity-Preserving Single- and Multi-Human Image Personalization**|Junjie He et.al.|[2408.05939](http://arxiv.org/abs/2408.05939)|**[link](https://github.com/junjiehe96/UniPortrait)**|
|**2024-07-31**|**Chat2Layout: Interactive 3D Furniture Layout with a Multimodal LLM**|Can Wang et.al.|[2407.21333](http://arxiv.org/abs/2407.21333)|null|
|**2024-07-29**|**SciPostLayout: A Dataset for Layout Analysis and Layout Generation of Scientific Posters**|Shohei Tanaka et.al.|[2407.19787](http://arxiv.org/abs/2407.19787)|null|
|**2024-11-22**|**LayoutDiT: Exploring Content-Graphic Balance in Layout Generation with Diffusion Transformer**|Yu Li et.al.|[2407.15233](http://arxiv.org/abs/2407.15233)|null|
|**2024-07-17**|**LTSim: Layout Transportation-based Similarity Measure for Evaluating Layout Generation**|Mayu Otani et.al.|[2407.12356](http://arxiv.org/abs/2407.12356)|null|
|**2024-10-22**|**UrbanWorld: An Urban World Model for 3D City Generation**|Yu Shang et.al.|[2407.11965](http://arxiv.org/abs/2407.11965)|**[link](https://github.com/urban-world/urbanworld)**|
|**2024-07-16**|**COHO: Context-Sensitive City-Scale Hierarchical Urban Layout Generation**|Liu He et.al.|[2407.11294](http://arxiv.org/abs/2407.11294)|**[link](https://github.com/arking1995/coho)**|
|**2024-07-13**|**Layout-and-Retouch: A Dual-stage Framework for Improving Diversity in Personalized Image Generation**|Kangyeol Kim et.al.|[2407.09779](http://arxiv.org/abs/2407.09779)|null|
|**2024-07-12**|**A Novel Framework for Automated Warehouse Layout Generation**|Atefeh Shahroudnejad et.al.|[2407.08633](http://arxiv.org/abs/2407.08633)|null|
|**2024-07-10**|**RoBus: A Multimodal Dataset for Controllable Road Networks and Building Layouts Generation**|Tao Li et.al.|[2407.07835](http://arxiv.org/abs/2407.07835)|**[link](https://github.com/tourlics/robus_dataset)**|
|**2024-05-27**|**Revision Matters: Generative Design Guided by Revision Edits**|Tao Li et.al.|[2406.18559](http://arxiv.org/abs/2406.18559)|null|
|**2024-06-12**|**DocSynthv2: A Practical Autoregressive Modeling for Document Generation**|Sanket Biswas et.al.|[2406.08354](http://arxiv.org/abs/2406.08354)|null|
|**2024-06-07**|**CityCraft: A Real Crafter for 3D City Generation**|Jie Deng et.al.|[2406.04983](http://arxiv.org/abs/2406.04983)|null|
|**2024-06-06**|**LLplace: The 3D Indoor Scene Layout Generation and Editing via Large Language Model**|Yixuan Yang et.al.|[2406.03866](http://arxiv.org/abs/2406.03866)|null|
|**2024-11-26**|**PosterLLaVa: Constructing a Unified Multi-modal Layout Generator with LLM**|Tao Yang et.al.|[2406.02884](http://arxiv.org/abs/2406.02884)|**[link](https://github.com/posterllava/posterllava)**|
|**2025-05-30**|**AutoStudio: Crafting Consistent Subjects in Multi-turn Interactive Image Generation**|Junhao Cheng et.al.|[2406.01388](http://arxiv.org/abs/2406.01388)|**[link](https://github.com/donahowe/AutoStudio)**|
|**2024-09-15**|**Layout Agnostic Scene Text Image Synthesis with Diffusion Models**|Qilong Zhangli et.al.|[2406.01062](http://arxiv.org/abs/2406.01062)|null|
|**2024-05-29**|**Automated Optimal Layout Generator for Animal Shelters: A framework based on Genetic Algorithm, TOPSIS and Graph Theory**|Arghavan Jalayer et.al.|[2405.14172](http://arxiv.org/abs/2405.14172)|null|
|**2024-05-18**|**CoLay: Controllable Layout Generation through Multi-conditional Latent Diffusion**|Chin-Yi Cheng et.al.|[2405.13045](http://arxiv.org/abs/2405.13045)|null|
|**2024-05-16**|**Leveraging Human Revisions for Improving Text-to-Layout Models**|Amber Xie et.al.|[2405.13026](http://arxiv.org/abs/2405.13026)|null|
|**2024-05-21**|**Physics-based Scene Layout Generation from Human Motion**|Jianan Li et.al.|[2405.12460](http://arxiv.org/abs/2405.12460)|null|
|**2024-05-13**|**Layout Generation Agents with Large Language Models**|Yuichi Sasazawa et.al.|[2405.08037](http://arxiv.org/abs/2405.08037)|**[link](https://github.com/ckdjrkffz/layout-agent)**|
|**2024-04-22**|**Graphic Design with Large Multimodal Model**|Yutao Cheng et.al.|[2404.14368](http://arxiv.org/abs/2404.14368)|**[link](https://github.com/graphic-design-ai/graphist)**|
|**2024-07-28**|**PosterLlama: Bridging Design Ability of Langauge Model to Contents-Aware Layout Generation**|Jaejung Seol et.al.|[2404.00995](http://arxiv.org/abs/2404.00995)|**[link](https://github.com/jaepoong/PosterLlama)**|
|**2024-03-30**|**SVGCraft: Beyond Single Object Text-to-SVG Synthesis with Comprehensive Canvas Layout**|Ayan Banerjee et.al.|[2404.00412](http://arxiv.org/abs/2404.00412)|**[link](https://github.com/ayanban011/svgcraft)**|
|**2024-03-30**|**Constrained Layout Generation with Factor Graphs**|Mohammed Haroon Dupty et.al.|[2404.00385](http://arxiv.org/abs/2404.00385)|null|
|**2024-07-13**|**LayoutFlow: Flow Matching for Layout Generation**|Julian Jorge Andrade Guerreiro et.al.|[2403.18187](http://arxiv.org/abs/2403.18187)|null|
|**2024-10-28**|**Refining Text-to-Image Generation: Towards Accurate Training-Free Glyph-Enhanced Image Generation**|Sanyam Lakhanpal et.al.|[2403.16422](http://arxiv.org/abs/2403.16422)|null|
|**2024-03-15**|**ChatPattern: Layout Pattern Customization via Natural Language**|Zixiao Wang et.al.|[2403.15434](http://arxiv.org/abs/2403.15434)|null|
|**2024-08-26**|**Planner3D: LLM-enhanced graph prior meets 3D indoor scene explicit regularization**|Yao Wei et.al.|[2403.12848](http://arxiv.org/abs/2403.12848)|null|
|**2024-07-20**|**OMG: Occlusion-friendly Personalized Multi-concept Generation in Diffusion Models**|Zhe Kong et.al.|[2403.10983](http://arxiv.org/abs/2403.10983)|**[link](https://github.com/kongzhecn/omg)**|
|**2024-02-05**|**Open-Universe Indoor Scene Generation using LLM Program Synthesis and Uncurated Object Databases**|Rio Aguina-Kang et.al.|[2403.09675](http://arxiv.org/abs/2403.09675)|null|
|**2024-05-15**|**Towards Aligned Layout Generation via Diffusion Model with Aesthetic Constraints**|Jian Chen et.al.|[2402.04754](http://arxiv.org/abs/2402.04754)|**[link](https://github.com/puar-playground/lace)**|
|**2024-02-07**|**Text2Street: Controllable Text-to-image Generation for Street Views**|Jinming Su et.al.|[2402.04504](http://arxiv.org/abs/2402.04504)|null|
|**2024-01-29**|**Spot the Error: Non-autoregressive Graphic Layout Generation with Wireframe Locator**|Jieru Lin et.al.|[2401.16375](http://arxiv.org/abs/2401.16375)|**[link](https://github.com/ffffatgoose/spoterror)**|
|**2024-01-15**|**Graph Transformer GANs with Graph Masked Modeling for Architectural Layout Generation**|Hao Tang et.al.|[2401.07721](http://arxiv.org/abs/2401.07721)|null|
|**2024-05-06**|**FurniScene: A Large-scale 3D Room Dataset with Intricate Furnishing Scenes**|Genghao Zhang et.al.|[2401.03470](http://arxiv.org/abs/2401.03470)|null|
|**2024-09-03**|**Planning and Rendering: Towards Product Poster Generation with Diffusion Models**|Zhaochen Li et.al.|[2312.08822](http://arxiv.org/abs/2312.08822)|null|
|**2025-04-11**|**CityGen: Infinite and Controllable City Layout Generation**|Jie Deng et.al.|[2312.01508](http://arxiv.org/abs/2312.01508)|null|
|**2023-11-30**|**Detailed Human-Centric Text Description-Driven Large Scene Synthesis**|Gwanghyun Kim et.al.|[2311.18654](http://arxiv.org/abs/2311.18654)|null|
|**2023-11-28**|**Reason out Your Layout: Evoking the Layout Master from Large Language Models for Text-to-Image Synthesis**|Xiaohui Chen et.al.|[2311.17126](http://arxiv.org/abs/2311.17126)|null|
|**2024-04-15**|**Retrieval-Augmented Layout Transformer for Content-Aware Layout Generation**|Daichi Horita et.al.|[2311.13602](http://arxiv.org/abs/2311.13602)|**[link](https://github.com/cyberagentailab/ralf)**|
|**2023-11-11**|**LayoutPrompter: Awaken the Design Ability of Large Language Models**|Jiawei Lin et.al.|[2311.06495](http://arxiv.org/abs/2311.06495)|**[link](https://github.com/microsoft/layoutgeneration)**|
|**2023-10-25**|**Dolfin: Diffusion Layout Transformers without Autoencoder**|Yilin Wang et.al.|[2310.16305](http://arxiv.org/abs/2310.16305)|null|
|**2023-10-24**|**UI Layout Generation with LLMs Guided by UI Grammar**|Yuwen Lu et.al.|[2310.15455](http://arxiv.org/abs/2310.15455)|null|
|**2023-10-21**|**Post-Layout Simulation Driven Analog Circuit Sizing**|Xiaohan Gao et.al.|[2310.14049](http://arxiv.org/abs/2310.14049)|null|
|**2025-05-23**|**Ctrl-Room: Controllable Text-to-3D Room Meshes Generation with Layout Constraints**|Chuan Fang et.al.|[2310.03602](http://arxiv.org/abs/2310.03602)|null|
|**2023-09-19**|**LayoutNUWA: Revealing the Hidden Layout Expertise of Large Language Models**|Zecheng Tang et.al.|[2309.09506](http://arxiv.org/abs/2309.09506)|**[link](https://github.com/projectnuwa/layoutnuwa)**|
|**2023-08-24**|**A Parse-Then-Place Approach for Generating Graphic Layouts from Textual Descriptions**|Jiawei Lin et.al.|[2308.12700](http://arxiv.org/abs/2308.12700)|null|
|**2023-08-23**|**AutoPoster: A Highly Automatic and Content-aware Design System for Advertising Poster Generation**|Jinpeng Lin et.al.|[2308.01095](http://arxiv.org/abs/2308.01095)|null|
|**2023-07-19**|**Generating Redstone Style Cities in Minecraft**|Shuo Huang et.al.|[2307.09777](http://arxiv.org/abs/2307.09777)|null|
|**2023-07-19**|**GlobalMapper: Arbitrary-Shaped Urban Layout Generation**|Liu He et.al.|[2307.09693](http://arxiv.org/abs/2307.09693)|null|
|**2023-07-18**|**Conditional 360-degree Image Synthesis for Immersive Indoor Scene Decoration**|Ka Chun Shum et.al.|[2307.09621](http://arxiv.org/abs/2307.09621)|null|
|**2024-01-11**|**Relation-Aware Diffusion Model for Controllable Poster Layout Generation**|Fengheng Li et.al.|[2306.09086](http://arxiv.org/abs/2306.09086)|**[link](https://github.com/liuan0803/radm)**|
|**2023-05-31**|**VMap: An Interactive Rectangular Space-filling Visualization for Map-like Vertex-centric Graph Exploration**|Jiayi Xu et.al.|[2306.00120](http://arxiv.org/abs/2306.00120)|null|
|**2023-05-30**|**TaleCrafter: Interactive Story Visualization with Multiple Characters**|Yuan Gong et.al.|[2305.18247](http://arxiv.org/abs/2305.18247)|**[link](https://github.com/videocrafter/talecrafter)**|
|**2023-10-27**|**Visual Programming for Text-to-Image Generation and Evaluation**|Jaemin Cho et.al.|[2305.15328](http://arxiv.org/abs/2305.15328)|null|
|**2023-05-22**|**Design a Delicious Lunchbox in Style**|Yutong Zhou et.al.|[2305.14522](http://arxiv.org/abs/2305.14522)|null|
|**2023-05-04**|**LayoutDM: Transformer-based Diffusion Model for Layout Generation**|Shang Chai et.al.|[2305.02567](http://arxiv.org/abs/2305.02567)|null|
|**2023-04-18**|**GUILGET: GUI Layout GEneration with Transformer**|Andrey Sobolevsky et.al.|[2304.09012](http://arxiv.org/abs/2304.09012)|**[link](https://github.com/dysoxor/guilget)**|
|**2023-03-25**|**Unsupervised Domain Adaption with Pixel-level Discriminator for Image-aware Layout Generation**|Chenchen Xu et.al.|[2303.14377](http://arxiv.org/abs/2303.14377)|null|
|**2023-08-15**|**LayoutDiffusion: Improving Graphic Layout Generation by Discrete Diffusion Probabilistic Models**|Junyi Zhang et.al.|[2303.11589](http://arxiv.org/abs/2303.11589)|**[link](https://github.com/microsoft/layoutgeneration)**|
|**2023-03-19**|**Diffusion-based Document Layout Generation**|Liu He et.al.|[2303.10787](http://arxiv.org/abs/2303.10787)|null|
|**2023-03-14**|**LayoutDM: Discrete Diffusion Model for Controllable Layout Generation**|Naoto Inoue et.al.|[2303.08137](http://arxiv.org/abs/2303.08137)|**[link](https://github.com/CyberAgentAILab/layout-dm)**|
|**2023-03-09**|**Unifying Layout Generation with a Decoupled Diffusion Model**|Mude Hui et.al.|[2303.05049](http://arxiv.org/abs/2303.05049)|null|
|**2023-03-07**|**DLT: Conditioned layout generation with Joint Discrete-Continuous Diffusion Layout Transformer**|Elad Levi et.al.|[2303.03755](http://arxiv.org/abs/2303.03755)|**[link](https://github.com/wix-incubator/DLT)**|
|**2023-06-21**|**PLay: Parametrically Conditioned Layout Generation using Latent Diffusion**|Chin-Yi Cheng et.al.|[2301.11529](http://arxiv.org/abs/2301.11529)|null|
|**2023-01-16**|**Diverse Multimedia Layout Generation with Multi Choice Learning**|David D. Nguyen et.al.|[2301.06629](http://arxiv.org/abs/2301.06629)|null|
|**2024-09-30**|**LayoutDETR: Detection Transformer Is a Good Multimodal Layout Designer**|Ning Yu et.al.|[2212.09877](http://arxiv.org/abs/2212.09877)|**[link](https://github.com/salesforce/layoutdetr)**|
|**2023-08-03**|**HS-Diffusion: Semantic-Mixing Diffusion for Head Swapping**|Qinghe Wang et.al.|[2212.06458](http://arxiv.org/abs/2212.06458)|**[link](https://github.com/qinghew/hs-diffusion)**|
|**2022-09-02**|**Geometry Aligned Variational Transformer for Image-conditioned Layout Generation**|Yunning Cao et.al.|[2209.00852](http://arxiv.org/abs/2209.00852)|null|
|**2023-03-24**|**LayoutFormer++: Conditional Graphic Layout Generation via Constraint Serialization and Decoding Space Restriction**|Zhaoyun Jiang et.al.|[2208.08037](http://arxiv.org/abs/2208.08037)|null|
|**2022-08-12**|**Layout-Bridging Text-to-Image Synthesis**|Jiadong Liang et.al.|[2208.06162](http://arxiv.org/abs/2208.06162)|null|
|**2022-07-24**|**A Custom IC Layout Generation Engine Based on Dynamic Templates and Grids**|Taeho Shin et.al.|[2207.11728](http://arxiv.org/abs/2207.11728)|null|
|**2023-08-27**|**ReCo: A Dataset for Residential Community Layout Planning**|Xi Chen et.al.|[2206.04678](http://arxiv.org/abs/2206.04678)|**[link](https://github.com/fdudsde/reco-dataset)**|
|**2022-07-13**|**Composition-aware Graphic Layout GAN for Visual-textual Presentation Designs**|Min Zhou et.al.|[2205.00303](http://arxiv.org/abs/2205.00303)|null|
|**2022-07-22**|**Structured Graph Variational Autoencoders for Indoor Furniture layout Generation**|Aditya Chattopadhyay et.al.|[2204.04867](http://arxiv.org/abs/2204.04867)|null|
|**2022-04-06**|**Aesthetic Text Logo Synthesis via Content-aware Layout Inferring**|Yizhi Wang et.al.|[2204.02701](http://arxiv.org/abs/2204.02701)|**[link](https://github.com/yizhiwang96/textlogolayout)**|
|**2022-03-31**|**Coverage hole detection in WSN with force-directed algorithm and transfer learning**|Yue-Hui Lai et.al.|[2204.01592](http://arxiv.org/abs/2204.01592)|null|
|**2022-03-28**|**Interactive Image Synthesis with Panoptic Layout Generation**|Bo Wang et.al.|[2203.02104](http://arxiv.org/abs/2203.02104)|**[link](https://github.com/wb-finalking/PLGAN)**|
|**2024-07-23**|**Cross-Domain Document Layout Analysis Using Document Style Guide**|Xingjiao Wu et.al.|[2201.09407](http://arxiv.org/abs/2201.09407)|null|
|**2021-12-10**|**Towards Full-to-Empty Room Generation with Structure-Aware Feature Encoding and Soft Semantic Region-Adaptive Normalization**|Vasileios Gkitsas et.al.|[2112.05396](http://arxiv.org/abs/2112.05396)|null|
|**2022-07-24**|**BLT: Bidirectional Layout Transformer for Controllable Layout Generation**|Xiang Kong et.al.|[2112.05112](http://arxiv.org/abs/2112.05112)|null|
|**2021-12-02**|**Multicriteria Scalable Graph Drawing via Stochastic Gradient Descent, $(SGD)^2$**|Reyan Ahmed et.al.|[2112.01571](http://arxiv.org/abs/2112.01571)|**[link](https://github.com/tiga1231/graph-drawing)**|
|**2022-01-06**|**The Layout Generation Algorithm of Graphic Design Based on Transformer-CVAE**|Mengxi Guo et.al.|[2110.06794](http://arxiv.org/abs/2110.06794)|null|
|**2021-08-02**|**Constrained Graphic Layout Generation via Latent Optimization**|Kotaro Kikuchi et.al.|[2108.00871](http://arxiv.org/abs/2108.00871)|**[link](https://github.com/ktrk115/const_layout)**|
|**2021-08-02**|**Automatic Polygon Layout for Primal-Dual Visualization of Hypergraphs**|Botong Qu et.al.|[2108.00671](http://arxiv.org/abs/2108.00671)|null|
|**2021-07-09**|**NVCell: Standard Cell Layout in Advanced Technology Nodes with Reinforcement Learning**|Haoxing Ren et.al.|[2107.07044](http://arxiv.org/abs/2107.07044)|null|
|**2021-07-09**|**Graph-based Deep Generative Modelling for Document Layout Generation**|Sanket Biswas et.al.|[2107.04357](http://arxiv.org/abs/2107.04357)|null|
|**2021-06-11**|**Toward Accurate and Realistic Outfits Visualization with Attention to Details**|Kedan Li et.al.|[2106.06593](http://arxiv.org/abs/2106.06593)|null|
|**2021-06-03**|**Semantic Palette: Guiding Scene Generation with Class Proportions**|Guillaume Le Moing et.al.|[2106.01629](http://arxiv.org/abs/2106.01629)|**[link](https://github.com/valeoai/SemanticPalette)**|
|**2021-04-27**|**Building-GAN: Graph-Conditioned Architectural Volumetric Design Generation**|Kai-Hung Chang et.al.|[2104.13316](http://arxiv.org/abs/2104.13316)|null|
|**2021-04-06**|**Variational Transformer Networks for Layout Generation**|Diego Martin Arroyo et.al.|[2104.02416](http://arxiv.org/abs/2104.02416)|null|
|**2021-03-15**|**GRIHA: Synthesizing 2-Dimensional Building Layouts from Images Captured using a Smart Phone**|Shreya Goyal et.al.|[2103.08297](http://arxiv.org/abs/2103.08297)|null|
|**2021-01-08**|**Geometry-Based Layout Generation with Hyper-Relations AMONG Objects**|Shao-Kui Zhang et.al.|[2101.02903](http://arxiv.org/abs/2101.02903)|**[link](https://github.com/Shao-Kui/3DScenePlatform)**|
|**2020-12-15**|**End-to-end Generative Floor-plan and Layout with Attributes and Relation Graph**|Xinhan Di et.al.|[2012.08514](http://arxiv.org/abs/2012.08514)|**[link](https://github.com/CODE-SUBMIT/dataset3)**|
|**2020-11-26**|**Generative Layout Modeling using Constraint Graphs**|Wamiq Para et.al.|[2011.13417](http://arxiv.org/abs/2011.13417)|**[link](https://github.com/wamiq-reyaz/generative-layout-modelling)**|
|**2020-10-10**|**Beyond Language: Learning Commonsense from Images for Reasoning**|Wanqing Cui et.al.|[2010.05001](http://arxiv.org/abs/2010.05001)|**[link](https://github.com/VickiCui/Loire)**|
|**2020-09-11**|**Attribute-conditioned Layout GAN for Automatic Graphic Design**|Jianan Li et.al.|[2009.05284](http://arxiv.org/abs/2009.05284)|null|
|**2020-08-28**|**Person-in-Context Synthesiswith Compositional Structural Space**|Weidong Yin et.al.|[2008.12679](http://arxiv.org/abs/2008.12679)|null|
|**2020-08-24**|**ALIGN: A System for Automating Analog Layout**|Tonmoy Dhar et.al.|[2008.10682](http://arxiv.org/abs/2008.10682)|null|
|**2020-08-15**|**Automatic Storage Structure Selection for hybrid Workload**|Hongzhi Wang et.al.|[2008.06640](http://arxiv.org/abs/2008.06640)|null|
|**2020-07-23**|**End-to-End Optimization of Scene Layout**|Andrew Luo et.al.|[2007.11744](http://arxiv.org/abs/2007.11744)|**[link](https://github.com/aluo-x/3D_SLN)**|
|**2020-07-14**|**2D Qubit Placement of Quantum Circuits using LONGPATH**|Mrityunjay Ghosh et.al.|[2007.06804](http://arxiv.org/abs/2007.06804)|null|
|**2021-09-30**|**LayoutTransformer: Layout Generation and Completion with Self-attention**|Kamal Gupta et.al.|[2006.14615](http://arxiv.org/abs/2006.14615)|null|
|**2020-07-07**|**Adversarial Model for Rotated Indoor Scenes Planning**|Xinhan Di et.al.|[2006.13527](http://arxiv.org/abs/2006.13527)|null|
|**2020-05-30**|**OPAL-Net: A Generative Model for Part-based Object Layout Generation**|Rishabh Baghel et.al.|[2006.00190](http://arxiv.org/abs/2006.00190)|null|
|**2020-03-16**|**House-GAN: Relational Generative Adversarial Networks for Graph-constrained House Layout Generation**|Nelson Nauata et.al.|[2003.06988](http://arxiv.org/abs/2003.06988)|null|
|**2020-03-12**|**Towards Photo-Realistic Virtual Try-On by Adaptively Generating $\leftrightarrow$ Preserving Image Content**|Han Yang et.al.|[2003.05863](http://arxiv.org/abs/2003.05863)|null|
|**2020-07-16**|**Neural Design Network: Graphic Layout Generation with Constraints**|Hsin-Ying Lee et.al.|[1912.09421](http://arxiv.org/abs/1912.09421)|null|
|**2019-12-12**|**Automatic Layout Generation with Applications in Machine Learning Engine Evaluation**|Haoyu Yang et.al.|[1912.05796](http://arxiv.org/abs/1912.05796)|**[link](https://github.com/phdyang007/layout-generator)**|
|**2019-09-19**|**Triplet-Aware Scene Graph Embeddings**|Brigit Schroeder et.al.|[1909.09256](http://arxiv.org/abs/1909.09256)|null|
|**2019-09-11**|**The NC-proximal average for multiple functions**|Warren Hare et.al.|[1909.06222](http://arxiv.org/abs/1909.06222)|null|
|**2019-11-13**|**Relationship-Aware Spatial Perception Fusion for Realistic Scene Layout Generation**|Hongdong Zheng et.al.|[1909.00640](http://arxiv.org/abs/1909.00640)|null|
|**2020-04-16**|**READ: Recursive Autoencoders for Document Layout Generation**|Akshay Gadi Patil et.al.|[1909.00302](http://arxiv.org/abs/1909.00302)|null|
|**2019-09-28**|**Continuous Graph Flow**|Zhiwei Deng et.al.|[1908.02436](http://arxiv.org/abs/1908.02436)|null|
|**2021-06-01**|**LayoutVAE: Stochastic Scene Layout Generation From a Label Set**|Akash Abdu Jyothi et.al.|[1907.10719](http://arxiv.org/abs/1907.10719)|null|
|**2019-01-21**|**LayoutGAN: Generating Graphic Layouts with Wireframe Discriminators**|Jianan Li et.al.|[1901.06767](http://arxiv.org/abs/1901.06767)|null|
|**2018-07-26**|**Inferring Semantic Layout for Hierarchical Text-to-Image Synthesis**|Seunghoon Hong et.al.|[1801.05091](http://arxiv.org/abs/1801.05091)|null|
|**2017-05-14**|**Novel CMOS RFIC Layout Generation with Concurrent Device Placement and Fixed-Length Microstrip Routing**|Tsun-Ming Tseng et.al.|[1705.04991](http://arxiv.org/abs/1705.04991)|null|
|**2016-07-01**|**PyCells for an Open Semiconductor Industry**|Sepideh Alassi et.al.|[1607.00859](http://arxiv.org/abs/1607.00859)|null|
|**2014-10-28**|**Two Novel Defenses against Motion-Based Keystroke Inference Attacks**|Yihang Song et.al.|[1410.7746](http://arxiv.org/abs/1410.7746)|null|
|**2013-07-26**|**Optimal Hierarchical Layouts for Cache-Oblivious Search Trees**|Peter Lindstrom et.al.|[1307.5899](http://arxiv.org/abs/1307.5899)|null|
|**2013-06-09**|**A Quantum Physical Design Flow Using ILP and Graph Drawing**|Maryam Yazdani et.al.|[1306.2037](http://arxiv.org/abs/1306.2037)|null|
|**2007-10-25**|**Multi-Placement Structures for Fast and Optimized Placement in Analog Circuit Synthesis**|Raoul F. Badaoui et.al.|[0710.4717](http://arxiv.org/abs/0710.4717)|null|

<p align=right>(<a href=#updated-on-20250806>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

